{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: tensorflow in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow_addons in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (4.6.0)\n",
      "Requirement already satisfied: imageio in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.21.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: setuptools in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: etils[epath] in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (0.7.1)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (1.10.0)\n",
      "Requirement already satisfied: promise in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: dill in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.5.1)\n",
      "Requirement already satisfied: toml in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: importlib-resources in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: zipp in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from etils[epath]->tensorflow_datasets) (3.8.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow tensorflow_addons tensorflow_datasets imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-25 17:03:11.673144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.679411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.679590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.680524: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-25 17:03:11.681222: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.681391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.681533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.965310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.965417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.965492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-25 17:03:11.965559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5758 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbed84548e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "# train_images = tf.image.resize(train_images, (32,32)) # if we want to resize \n",
    "train_images = tf.expand_dims(train_images, -1)\n",
    "train_images = tf.image.resize(train_images, (32,32))\n",
    "print(train_images.shape)\n",
    "plt.imshow(train_images[6, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-grayscale image should be normalized to [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the network size for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "\n",
    "    def __init__(self, noise_dim, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 5.0), 11.0))\n",
    "\n",
    "        self.lr_d = layers.LeakyReLU()\n",
    "        self.lr_c1 = layers.LeakyReLU()\n",
    "        self.lr_c2 = layers.LeakyReLU()\n",
    "        self.lr_c3 = layers.LeakyReLU()\n",
    "        \n",
    "        self.init_dense = layers.Dense(image_shape[0]/8.0*image_shape[1]/8.0*64,\n",
    "                               use_bias=False, input_shape=(self.noise_dim,))\n",
    "        \n",
    "        self.init_reshape = layers.Reshape((int(image_shape[0]/8.0), int(image_shape[1]/8.0), 64))\n",
    "        \n",
    "        self.conv2dT1 = layers.Conv2DTranspose(32, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(1, 1), padding='same', use_bias=False)\n",
    "        self.conv2dT2 = layers.Conv2DTranspose(16, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.conv2dT3 = layers.Conv2DTranspose(8, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.conv2dTactv = layers.Conv2DTranspose(self.num_channel, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "\n",
    "    def call(self, noise_vec):\n",
    "\n",
    "        init_vec = tf.squeeze(self.lr_d(self.init_dense(noise_vec)))\n",
    "        \n",
    "#         print(init_vec.shape)\n",
    "        \n",
    "        reshaped = self.init_reshape(init_vec)\n",
    "        \n",
    "#         print(reshaped.shape)\n",
    "        \n",
    "        convt1 = self.lr_c1(self.conv2dT1(reshaped))\n",
    "\n",
    "#         print(convt1.shape)\n",
    "        \n",
    "        convt2 = self.lr_c2(self.conv2dT2(convt1))\n",
    "        \n",
    "#         print(convt2.shape)\n",
    "                         \n",
    "        convt3 = self.lr_c3(self.conv2dT3(convt2))\n",
    "        \n",
    "#         print(convt3.shape)\n",
    "            \n",
    "        out = self.conv2dTactv(convt3)\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Generator(10, (32, 32), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(5, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "print(noise_input.shape)\n",
    "pics1 = g1(tf.expand_dims(noise_input, 0))\n",
    "print(pics1.shape)\n",
    "# plt.imshow(pics1[-1, :, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " leaky_re_lu_48 (LeakyReLU)  multiple                  0         \n",
      "                                                                 \n",
      " leaky_re_lu_49 (LeakyReLU)  multiple                  0         \n",
      "                                                                 \n",
      " leaky_re_lu_50 (LeakyReLU)  multiple                  0         \n",
      "                                                                 \n",
      " leaky_re_lu_51 (LeakyReLU)  multiple                  0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  10240     \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         multiple                  0         \n",
      "                                                                 \n",
      " conv2d_transpose_36 (Conv2D  multiple                 51200     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_37 (Conv2D  multiple                 12800     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_38 (Conv2D  multiple                 3200      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_39 (Conv2D  multiple                 600       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 78,040\n",
      "Trainable params: 78,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "\n",
    "    def __init__(self, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 5.0), 11.0))\n",
    "\n",
    "        self.lr_c1 = layers.LeakyReLU()\n",
    "        self.lr_c2 = layers.LeakyReLU()\n",
    "        self.lr_c3 = layers.LeakyReLU()\n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.conv2d1 = layers.Conv2D(16, (self.kernel_size, self.kernel_size),\n",
    "                                        strides=(2, 2), padding='same',\n",
    "                                        input_shape=(None, self.image_shape[0],\n",
    "                                        self.image_shape[1], self.num_channel))\n",
    "        self.conv2d2 = layers.Conv2D(32, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2d3 = layers.Conv2D(64, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.dense_actv = layers.Dense(256,\n",
    "                                      )\n",
    "#                                        activation=\"relu\")\n",
    "        \n",
    "    def call(self, img_input):\n",
    "        \n",
    "        conv1 = self.lr_c1(self.conv2d1(img_input))\n",
    "        \n",
    "#         print(conv1.shape)\n",
    "        \n",
    "        conv2 = self.lr_c2(self.conv2d2(conv1))\n",
    "        \n",
    "#         print(conv2.shape)\n",
    "                         \n",
    "        conv3 = self.lr_c3(self.conv2d3(conv2))\n",
    "        \n",
    "#         print(conv3.shape)\n",
    "        \n",
    "        flat = self.flatten(conv3)\n",
    "        \n",
    "#         print(flat.shape)\n",
    "        \n",
    "        out = tf.squeeze(self.dense_actv(flat))\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = Discriminator((32,32), 3)\n",
    "g2 = Generator(10, (32,32), 3)\n",
    "d1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "pics2 = g1(tf.expand_dims(noise_input, 0))\n",
    "# plt.imshow(pics2[-1, :, :, 0], cmap='gray')\n",
    "print(pics2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 256])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deci = d1(pics2)\n",
    "deci.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " leaky_re_lu_220 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " leaky_re_lu_221 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " leaky_re_lu_222 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " conv2d_84 (Conv2D)          multiple                  1216      \n",
      "                                                                 \n",
      " conv2d_85 (Conv2D)          multiple                  12832     \n",
      "                                                                 \n",
      " conv2d_86 (Conv2D)          multiple                  51264     \n",
      "                                                                 \n",
      " dense_62 (Dense)            multiple                  262400    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 327,712\n",
      "Trainable params: 327,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-10\n",
    "\n",
    "class DCGAN:\n",
    "    \n",
    "    def __init__(self, dataset, image_shape, num_channel, noise_latent_dim,\n",
    "                 buffer_size=60000, batch_size=256, lr=3e-4, gp_lam = 0.5):\n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        assert len(dataset.shape) == 4\n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.noise_latent_dim = noise_latent_dim\n",
    "        self.buffer_cap, self.batch_size, self.gp_lam = buffer_size, batch_size, gp_lam\n",
    "        self.num_img_prog_monit = 16\n",
    "        \n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices(tf.image.resize(dataset,\n",
    "                                                                          self.image_shape)).shuffle(self.buffer_cap).batch(self.batch_size)\n",
    "        # NOTE: Dataset must be processed differently for different source and applications\n",
    "        \n",
    "        self.g = Generator(self.noise_latent_dim, self.image_shape, self.num_channel)\n",
    "        self.d = Discriminator(self.image_shape, self.num_channel)\n",
    "        \n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr)\n",
    "        \n",
    "        self.g_seed = tf.random.normal((self.num_img_prog_monit, self.noise_latent_dim))\n",
    "\n",
    "    def cramer_loss(self, d_x_data, d_g_z_1, d_g_z_2, x_it):\n",
    "        \n",
    "        crit_r = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1)),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_x_data**2, axis = 1)))\n",
    "        crit_g_1 = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1)),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_g_z_1**2, axis = 1)))\n",
    "        \n",
    "        L_srg = tf.math.add(crit_r, -crit_g_1)\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d(x_it)\n",
    "            crit_it = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_it, -d_g_z_2)**2, axis = 1)),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_it**2, axis = 1)))\n",
    "            \n",
    "        gp_grad = t_gp.gradient(crit_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3]))\n",
    "        \n",
    "        # d_loss\n",
    "        L_d = -L_srg + (self.gp_lam*((l2n_gp-1)**2))\n",
    "\n",
    "        l2nrg1 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_1)**2, axis = 1))\n",
    "        l2nrg2 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1))\n",
    "        l2ng12 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1))\n",
    "\n",
    "        # g_loss\n",
    "        L_g = (l2nrg1 + l2nrg2 - l2ng12)\n",
    "\n",
    "        return L_g, L_d\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def update(self, imgs):\n",
    "        noise_input1 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        noise_input2 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            g_z_1 = self.g(noise_input1, training=True)\n",
    "            g_z_2 = self.g(noise_input2, training=True)\n",
    "            \n",
    "            d_x_data = self.d(imgs, training=True)\n",
    "            d_g_z_1 = self.d(g_z_1, training=True)\n",
    "            d_g_z_2 = self.d(g_z_2, training=True)\n",
    "            \n",
    "            epsi = tf.random.normal((1,))\n",
    "            x_it = tf.math.add(epsi*imgs, (1.0-epsi)*g_z_1)\n",
    "\n",
    "            g_loss, d_loss = self.cramer_loss(d_x_data, d_g_z_1, d_g_z_2, x_it)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "        \n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        \n",
    "        return g_loss, d_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            for img_b in self.dataset:\n",
    "                g_l, d_l = self.update(img_b)\n",
    "            print(\"Generator Loss: \", tf.reduce_mean(g_l), \", Discriminator Loss: \",  tf.reduce_mean(d_l))\n",
    "            self.monitor_progress(epo)\n",
    "            \n",
    "    def monitor_progress(self, epo):\n",
    "        pics = self.g(self.g_seed, training=False)\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(pics.shape[0]):\n",
    "            plt.subplot(4,4,i+1)\n",
    "            plt.imshow(pics[i,:,:,0]*127.5+127.5,cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "\n",
    "        \n",
    "        plt.savefig('/home/tony/TO_BE_REMOVED/imgs/image_{:04d}.png'.format(epo))\n",
    "        # NEEDS to be changed for machines\n",
    "        \n",
    "        plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_images = tf.expand_dims(train_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan1 = DCGAN(train_images, (32,32), 1, 100)\n",
    "d1 = Discriminator((32,32), 1)\n",
    "g1 = Generator(10, (32,32), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "noise_input1 = tf.random.normal((256, 10))\n",
    "noise_input2 = tf.random.normal((256, 10))\n",
    "noise_input3 = tf.random.normal((256, 10))\n",
    "pics3 = g1(tf.expand_dims(noise_input1, 0))\n",
    "pics4 = g1(tf.expand_dims(noise_input2, 0))\n",
    "pics5 = g1(tf.expand_dims(noise_input3, 0))\n",
    "d_pics3 = d1(pics3)\n",
    "d_pics4 = d1(pics4)\n",
    "d_pics5 = d1(pics5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Loss:  tf.Tensor(54986.035, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(106.00051, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(4287.3833, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(-49.075756, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(75049.11, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(-293.86526, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(490771.88, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(-22894.508, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(714731.2, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(864.39453, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n",
      "Generator Loss:  tf.Tensor(nan, shape=(), dtype=float32) , Discriminator Loss:  tf.Tensor(nan, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/numpy/core/fromnumeric.py:40\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_wrap__\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute '__array_wrap__'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [159]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdcgan1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [155]\u001b[0m, in \u001b[0;36mDCGAN.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     g_l, d_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(img_b)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerator Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39mreduce_mean(g_l), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, Discriminator Loss: \u001b[39m\u001b[38;5;124m\"\u001b[39m,  tf\u001b[38;5;241m.\u001b[39mreduce_mean(d_l))\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonitor_progress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepo\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [155]\u001b[0m, in \u001b[0;36mDCGAN.monitor_progress\u001b[0;34m(self, epo)\u001b[0m\n\u001b[1;32m     96\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(pics\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 98\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(pics[i,:,:,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m127.5\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m127.5\u001b[39m,cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    100\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/pyplot.py:1302\u001b[0m, in \u001b[0;36msubplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1301\u001b[0m     \u001b[38;5;66;03m# we have exhausted the known Axes and none match, make a new one!\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_subplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m fig\u001b[38;5;241m.\u001b[39msca(ax)\n\u001b[1;32m   1306\u001b[0m bbox \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mbbox\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/figure.py:772\u001b[0m, in \u001b[0;36mFigureBase.add_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m])))\n\u001b[1;32m    770\u001b[0m     projection_class, pkw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_projection_requirements(\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 772\u001b[0m     ax \u001b[38;5;241m=\u001b[39m \u001b[43msubplot_class_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprojection_class\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    773\u001b[0m     key \u001b[38;5;241m=\u001b[39m (projection_class, pkw)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_axes_internal(ax, key)\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/axes/_subplots.py:34\u001b[0m, in \u001b[0;36mSubplotBase.__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    Keyword arguments are passed to the Axes (sub)class constructor.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# _axes_class is set in the subplot_class_factory\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_axes_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# This will also update the axes position.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_subplotspec(SubplotSpec\u001b[38;5;241m.\u001b[39m_from_subplot_args(fig, args))\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[1;32m    454\u001b[0m     warn_deprecated(\n\u001b[1;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/axes/_base.py:632\u001b[0m, in \u001b[0;36m_AxesBase.__init__\u001b[0;34m(self, fig, rect, facecolor, frameon, sharex, sharey, label, xscale, yscale, box_aspect, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_axisbelow(mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes.axisbelow\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rasterization_zorder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcla\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;66;03m# funcs used to format x and y - fall back on major formatters\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt_xdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/axes/_base.py:1302\u001b[0m, in \u001b[0;36m_AxesBase.cla\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_axis_on()\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mset_clip_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch)\n\u001b[0;32m-> 1302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_axes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclean()\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shared_axes[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mclean()\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/axis.py:937\u001b[0m, in \u001b[0;36mAxis.set_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmajorTicks \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminorTicks:\n\u001b[0;32m--> 937\u001b[0m     \u001b[43mchild\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclippath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/axis.py:239\u001b[0m, in \u001b[0;36mTick.set_clip_path\u001b[0;34m(self, clippath, transform)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_clip_path\u001b[39m(\u001b[38;5;28mself\u001b[39m, clippath, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mset_clip_path(clippath, transform)\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgridline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_clip_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclippath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/artist.py:791\u001b[0m, in \u001b[0;36mArtist.set_clip_path\u001b[0;34m(self, path, transform)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, Rectangle):\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclipbox \u001b[38;5;241m=\u001b[39m TransformedBbox(Bbox\u001b[38;5;241m.\u001b[39munit(),\n\u001b[0;32m--> 791\u001b[0m                                        \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clippath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    793\u001b[0m         success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/patches.py:278\u001b[0m, in \u001b[0;36mPatch.get_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the `~.transforms.Transform` applied to the `Patch`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_patch_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m artist\u001b[38;5;241m.\u001b[39mArtist\u001b[38;5;241m.\u001b[39mget_transform(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/patches.py:758\u001b[0m, in \u001b[0;36mRectangle.get_patch_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_patch_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;66;03m# Note: This cannot be called until after this has been added to\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# an Axes, otherwise unit conversion will fail. This makes it very\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;66;03m# important to call the accessor method and not directly access the\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;66;03m# transformation member variable.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (transforms\u001b[38;5;241m.\u001b[39mBboxTransformTo(bbox)\n\u001b[1;32m    760\u001b[0m             \u001b[38;5;241m+\u001b[39m transforms\u001b[38;5;241m.\u001b[39mAffine2D()\u001b[38;5;241m.\u001b[39mrotate_deg_around(\n\u001b[1;32m    761\u001b[0m                 bbox\u001b[38;5;241m.\u001b[39mx0, bbox\u001b[38;5;241m.\u001b[39my0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle))\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/patches.py:851\u001b[0m, in \u001b[0;36mRectangle.get_bbox\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;124;03m\"\"\"Return the `.Bbox`.\"\"\"\u001b[39;00m\n\u001b[1;32m    850\u001b[0m x0, y0, x1, y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_units()\n\u001b[0;32m--> 851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/matplotlib/transforms.py:839\u001b[0m, in \u001b[0;36mBbox.from_extents\u001b[0;34m(minpos, *args)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_extents\u001b[39m(\u001b[38;5;241m*\u001b[39margs, minpos\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m    Create a new Bbox from *left*, *bottom*, *right* and *top*.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;124;03m       scales where negative bounds result in floating point errors.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 839\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m Bbox(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m minpos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    841\u001b[0m         bbox\u001b[38;5;241m.\u001b[39m_minpos[:] \u001b[38;5;241m=\u001b[39m minpos\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/numpy/core/fromnumeric.py:54\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     52\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.8/site-packages/numpy/core/fromnumeric.py:40\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapit\u001b[39m(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m         wrap \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_wrap__\u001b[49m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAACnCAYAAACcs67uAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACK0lEQVR4nO3UsRHAIBDAsJD9d34W4NxCIU3gymtm5gPg6L8dAPAykwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYBgkgDBJAGCSQIEkwQIJgkQTBIgmCRAMEmAYJIAwSQBgkkCBJMECCYJEEwSIJgkQDBJgGCSAMEkAYJJAgSTBAgmCRBMEiCYJEAwSYCwAc4TBUprXAOyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 400x400 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dcgan1.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
