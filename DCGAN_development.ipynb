{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: tensorflow in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow_addons in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (4.5.2)\n",
      "Requirement already satisfied: imageio in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.21.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: setuptools in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: dill in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (1.10.0)\n",
      "Requirement already satisfied: importlib-resources in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: promise in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from importlib-resources->tensorflow_datasets) (3.8.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow tensorflow_addons tensorflow_datasets imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/home/tony/TO_BE_REMOVED/celeba_data/imgs/\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_images = tf.image.resize(train_images, (32,32)) # if we want to resize \n",
    "# train_images = tf.expand_dims(train_images, -1)\n",
    "# train_images = tf.image.resize(train_images, (32,32))\n",
    "# print(train_images.shape)\n",
    "# plt.imshow(train_images[6, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-grayscale image should be normalized to [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the network size for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "\n",
    "    def __init__(self, noise_dim, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 3.0), 9.0))\n",
    "\n",
    "        self.lr_d = layers.ReLU()\n",
    "        self.lr_c1 = layers.ReLU()\n",
    "        self.lr_c2 = layers.ReLU()\n",
    "        self.lr_c3 = layers.ReLU()\n",
    "        \n",
    "        self.init_dense = layers.Dense(image_shape[0]/8.0*image_shape[1]/8.0*256,\n",
    "                               use_bias=False, input_shape=(self.noise_dim,))\n",
    "        \n",
    "        self.init_reshape = layers.Reshape((int(image_shape[0]/8.0), int(image_shape[1]/8.0), 256))\n",
    "        \n",
    "        self.conv2dT1 = layers.Conv2DTranspose(256, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(1, 1), padding='same')\n",
    "        self.conv2dT2 = layers.Conv2DTranspose(128, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2dT3 = layers.Conv2DTranspose(64, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2dTactv = layers.Conv2DTranspose(self.num_channel, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same', activation='tanh')\n",
    "\n",
    "    def call(self, noise_vec):\n",
    "\n",
    "        init_vec = tf.squeeze(self.lr_d(self.init_dense(noise_vec)))\n",
    "        \n",
    "#         print(init_vec.shape)\n",
    "        \n",
    "        reshaped = self.init_reshape(init_vec)\n",
    "        \n",
    "#         print(reshaped.shape)\n",
    "        \n",
    "        convt1 = self.lr_c1(self.conv2dT1(reshaped))\n",
    "\n",
    "#         print(convt1.shape)\n",
    "        \n",
    "        convt2 = self.lr_c2(self.conv2dT2(convt1))\n",
    "        \n",
    "#         print(convt2.shape)\n",
    "                         \n",
    "        convt3 = self.lr_c3(self.conv2dT3(convt2))\n",
    "        \n",
    "#         print(convt3.shape)\n",
    "            \n",
    "        out = self.conv2dTactv(convt3)\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Generator(10, (32, 32), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(5, 32, 32, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-28 10:35:40.592561: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-08-28 10:35:40.594448: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2022-08-28 10:35:40.594458: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-08-28 10:35:40.594753: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "print(noise_input.shape)\n",
    "pics1 = g1(tf.expand_dims(noise_input, 0))\n",
    "print(pics1.shape)\n",
    "# plt.imshow(pics1[-1, :, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " re_lu (ReLU)                multiple                  0         \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  40960     \n",
      "                                                                 \n",
      " reshape (Reshape)           multiple                  0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  multiple                 590080    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  multiple                 295040    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  multiple                 73792     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  multiple                 1731      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,001,603\n",
      "Trainable params: 1,001,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "\n",
    "    def __init__(self, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 3.0), 9.0))\n",
    "\n",
    "        self.lr_c1 = layers.LeakyReLU()\n",
    "        self.lr_c2 = layers.LeakyReLU()\n",
    "        self.lr_c3 = layers.LeakyReLU()\n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.conv2d1 = layers.Conv2D(64, (self.kernel_size, self.kernel_size),\n",
    "                                        strides=(2, 2), padding='same',\n",
    "                                        input_shape=(None, self.image_shape[0],\n",
    "                                        self.image_shape[1], self.num_channel))\n",
    "        self.conv2d2 = layers.Conv2D(128, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2d3 = layers.Conv2D(256, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.dense_actv = layers.Dense(256,\n",
    "                                      )\n",
    "#                                        activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self, img_input):\n",
    "        \n",
    "        conv1 = self.lr_c1(self.conv2d1(img_input))\n",
    "        \n",
    "#         print(conv1.shape)\n",
    "        \n",
    "        conv2 = self.lr_c2(self.conv2d2(conv1))\n",
    "        \n",
    "#         print(conv2.shape)\n",
    "                         \n",
    "        conv3 = self.lr_c3(self.conv2d3(conv2))\n",
    "        \n",
    "#         print(conv3.shape)\n",
    "        \n",
    "        flat = self.flatten(conv3)\n",
    "        \n",
    "#         print(flat.shape)\n",
    "        \n",
    "        out = tf.squeeze(self.dense_actv(flat))\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = Discriminator((32,32), 3)\n",
    "g2 = Generator(10, (32,32), 3)\n",
    "d1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "pics2 = g1(tf.expand_dims(noise_input, 0))\n",
    "# plt.imshow(pics2[-1, :, :, 0], cmap='gray')\n",
    "print(pics2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 256), dtype=float32, numpy=\n",
       "array([[ 7.4471725e-05, -6.6463414e-05,  1.2868243e-04, ...,\n",
       "         2.4515335e-04,  1.5570488e-04, -3.6045694e-05],\n",
       "       [ 7.0020978e-05,  1.9221421e-05,  1.1601584e-04, ...,\n",
       "         9.4312054e-05, -1.5467704e-04, -4.8234925e-04],\n",
       "       [ 6.8359470e-05,  4.0314870e-04,  4.4166239e-04, ...,\n",
       "        -1.4375307e-04, -1.9130563e-05, -2.3958864e-04],\n",
       "       [ 1.2065447e-04,  5.2060367e-04,  7.2034937e-04, ...,\n",
       "         8.3339590e-05, -2.1140157e-04, -4.8143476e-05],\n",
       "       [-1.4379679e-05,  5.2060338e-04,  9.6209795e-04, ...,\n",
       "         2.5674430e-04, -7.7900680e-05, -4.2041403e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deci = d1(pics2)\n",
    "deci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " leaky_re_lu (LeakyReLU)     multiple                  0         \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   multiple                  0         \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   multiple                  0         \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             multiple                  1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           multiple                  73856     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           multiple                  295168    \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1048832   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,419,648\n",
      "Trainable params: 1,419,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CramerDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class DCGAN:\n",
    "    \n",
    "    def __init__(self, dataset, image_shape, num_channel, noise_latent_dim,\n",
    "                 buffer_size=60000, batch_size=256, lr=3e-4, gp_lam = 10.0):\n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.noise_latent_dim = noise_latent_dim\n",
    "        self.buffer_cap, self.batch_size, self.gp_lam = buffer_size, batch_size, gp_lam\n",
    "        self.num_img_prog_monit = 16\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        # NOTE: Dataset must be processed differently for different source and applications\n",
    "        \n",
    "        self.g = Generator(self.noise_latent_dim, self.image_shape, self.num_channel)\n",
    "        self.d = Discriminator(self.image_shape, self.num_channel)\n",
    "        \n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr)\n",
    "        \n",
    "        self.g_seed = tf.random.normal((self.num_img_prog_monit, self.noise_latent_dim))\n",
    "\n",
    "    def cramer_loss(self, d_x_data, d_g_z_1, d_g_z_2, x_it):\n",
    "        \n",
    "        crit_r = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_x_data**2, axis = 1)+EPSILON))\n",
    "        crit_g_1 = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_g_z_1**2, axis = 1)+EPSILON))\n",
    "        \n",
    "        L_srg = tf.math.add(crit_r, -crit_g_1)\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d(x_it)\n",
    "            crit_it = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_it, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_it**2, axis = 1)+EPSILON))\n",
    "            \n",
    "        gp_grad = t_gp.gradient(crit_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3])+EPSILON)\n",
    "        \n",
    "        # d_loss\n",
    "        L_d = tf.reduce_mean(-L_srg + (self.gp_lam*((l2n_gp-1.0)**2)))\n",
    "\n",
    "        l2nrg1 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_1)**2, axis = 1)+EPSILON)\n",
    "        l2nrg2 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1)+EPSILON)\n",
    "        l2ng12 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1)+EPSILON)\n",
    "\n",
    "        # g_loss\n",
    "        L_g = tf.reduce_mean(l2nrg1 + l2nrg2 - l2ng12)\n",
    "\n",
    "        return L_g, L_d\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def update(self, imgs):\n",
    "        noise_input1 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        noise_input2 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            g_z_1 = self.g(noise_input1)\n",
    "            g_z_2 = self.g(noise_input2)\n",
    "            \n",
    "            d_x_data = self.d(imgs)\n",
    "            d_g_z_1 = self.d(g_z_1)\n",
    "            d_g_z_2 = self.d(g_z_2)\n",
    "            \n",
    "            epsi = tf.random.uniform([imgs.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "            x_it = tf.math.add(epsi*imgs, (1.0-epsi)*g_z_1)\n",
    "            g_loss, d_loss = self.cramer_loss(d_x_data, d_g_z_1, d_g_z_2, x_it)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "        \n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        return g_loss, d_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            for img_b, l_b in self.dataset:\n",
    "                norm_img_b = (img_b-127.5)/127.5\n",
    "                g_l, d_l = self.update(norm_img_b)\n",
    "            print(\"Generator Loss: \", g_l, \", Discriminator Loss: \",  d_l)\n",
    "            \n",
    "            self.monitor_progress(epo)\n",
    "            \n",
    "    def monitor_progress(self, epo):\n",
    "        pics = self.g(self.g_seed)\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(pics.shape[0]):\n",
    "            plt.subplot(4,4,i+1)\n",
    "            plt.imshow(tf.cast(tf.math.round(pics[i,:,:,:]*127.5+127.5), tf.int32))\n",
    "            plt.axis('off')\n",
    "            \n",
    "#         plt.savefig('/Users/anthonylaw/Desktop/Hustle/GAN-devel/imgs/image_{:04d}.png'.format(epo))\n",
    "        plt.savefig('/home/tony/TO_BE_REMOVED/imgs/image_{:04d}.png'.format(epo))\n",
    "        # NEEDS to be changed for machines\n",
    "        \n",
    "        plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/home/tony/TO_BE_REMOVED/celeba_data/imgs/\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan1 = DCGAN(train_ds, (64, 64), 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dcgan1.train(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
