{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: tensorflow in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorflow_addons in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (0.17.1)\n",
      "Requirement already satisfied: tensorflow_datasets in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (4.5.2)\n",
      "Requirement already satisfied: imageio in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (2.21.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (1.21.6)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (63.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_addons) (2.13.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (1.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.28.1)\n",
      "Requirement already satisfied: tqdm in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (4.64.0)\n",
      "Requirement already satisfied: dill in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (0.3.5.1)\n",
      "Requirement already satisfied: importlib-resources in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (5.9.0)\n",
      "Requirement already satisfied: promise in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow_datasets) (2.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from importlib-resources->tensorflow_datasets) (3.8.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from tensorflow-metadata->tensorflow_datasets) (1.56.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/tony/miniconda3/envs/gan/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow tensorflow_addons tensorflow_datasets imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/home/tony/TO_BE_REMOVED/celeba_data/imgs/\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_images = tf.image.resize(train_images, (32,32)) # if we want to resize \n",
    "# train_images = tf.expand_dims(train_images, -1)\n",
    "# train_images = tf.image.resize(train_images, (32,32))\n",
    "# print(train_images.shape)\n",
    "# plt.imshow(train_images[6, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-grayscale image should be normalized to [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the network size for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(Model):\n",
    "\n",
    "    def __init__(self, noise_dim, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.noise_dim = noise_dim\n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 3.0), 9.0))\n",
    "\n",
    "        self.lr_d = layers.ReLU()\n",
    "        self.lr_c1 = layers.ReLU()\n",
    "        self.lr_c2 = layers.ReLU()\n",
    "        self.lr_c3 = layers.ReLU()\n",
    "        \n",
    "        self.init_dense = layers.Dense(image_shape[0]/8.0*image_shape[1]/8.0*256,\n",
    "                               use_bias=False, input_shape=(self.noise_dim,))\n",
    "        \n",
    "        self.init_reshape = layers.Reshape((int(image_shape[0]/8.0), int(image_shape[1]/8.0), 256))\n",
    "        \n",
    "        self.conv2dT1 = layers.Conv2DTranspose(256, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(1, 1), padding='same')\n",
    "        self.conv2dT2 = layers.Conv2DTranspose(128, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2dT3 = layers.Conv2DTranspose(64, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2dTactv = layers.Conv2DTranspose(self.num_channel, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same', activation='tanh')\n",
    "\n",
    "    def call(self, noise_vec):\n",
    "\n",
    "        init_vec = tf.squeeze(self.lr_d(self.init_dense(noise_vec)))\n",
    "        \n",
    "#         print(init_vec.shape)\n",
    "        \n",
    "        reshaped = self.init_reshape(init_vec)\n",
    "        \n",
    "#         print(reshaped.shape)\n",
    "        \n",
    "        convt1 = self.lr_c1(self.conv2dT1(reshaped))\n",
    "\n",
    "#         print(convt1.shape)\n",
    "        \n",
    "        convt2 = self.lr_c2(self.conv2dT2(convt1))\n",
    "        \n",
    "#         print(convt2.shape)\n",
    "                         \n",
    "        convt3 = self.lr_c3(self.conv2dT3(convt2))\n",
    "        \n",
    "#         print(convt3.shape)\n",
    "            \n",
    "        out = self.conv2dTactv(convt3)\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = Generator(10, (32, 32), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(5, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "print(noise_input.shape)\n",
    "pics1 = g1(tf.expand_dims(noise_input, 0))\n",
    "print(pics1.shape)\n",
    "# plt.imshow(pics1[-1, :, :, :], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator_147\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " re_lu_588 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " re_lu_589 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " re_lu_590 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " re_lu_591 (ReLU)            multiple                  0         \n",
      "                                                                 \n",
      " dense_265 (Dense)           multiple                  40960     \n",
      "                                                                 \n",
      " reshape_147 (Reshape)       multiple                  0         \n",
      "                                                                 \n",
      " conv2d_transpose_588 (Conv2  multiple                 590080    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_589 (Conv2  multiple                 295040    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_590 (Conv2  multiple                 73792     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " conv2d_transpose_591 (Conv2  multiple                 1731      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,001,603\n",
      "Trainable params: 1,001,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "g1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(Model):\n",
    "\n",
    "    def __init__(self, image_shape, num_channel):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.kernel_size = int(min(max(min(image_shape[0]/8.0-3.0, image_shape[1]/8.0-3.0), 3.0), 9.0))\n",
    "\n",
    "        self.lr_c1 = layers.LeakyReLU()\n",
    "        self.lr_c2 = layers.LeakyReLU()\n",
    "        self.lr_c3 = layers.LeakyReLU()\n",
    "        self.flatten = layers.Flatten()\n",
    "        \n",
    "        self.conv2d1 = layers.Conv2D(64, (self.kernel_size, self.kernel_size),\n",
    "                                        strides=(2, 2), padding='same',\n",
    "                                        input_shape=(None, self.image_shape[0],\n",
    "                                        self.image_shape[1], self.num_channel))\n",
    "        self.conv2d2 = layers.Conv2D(128, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.conv2d3 = layers.Conv2D(256, (self.kernel_size, self.kernel_size),\n",
    "                                               strides=(2, 2), padding='same')\n",
    "        self.dense_actv = layers.Dense(256,\n",
    "                                      )\n",
    "#                                        activation=\"sigmoid\")\n",
    "        \n",
    "    def call(self, img_input):\n",
    "        \n",
    "        conv1 = self.lr_c1(self.conv2d1(img_input))\n",
    "        \n",
    "#         print(conv1.shape)\n",
    "        \n",
    "        conv2 = self.lr_c2(self.conv2d2(conv1))\n",
    "        \n",
    "#         print(conv2.shape)\n",
    "                         \n",
    "        conv3 = self.lr_c3(self.conv2d3(conv2))\n",
    "        \n",
    "#         print(conv3.shape)\n",
    "        \n",
    "        flat = self.flatten(conv3)\n",
    "        \n",
    "#         print(flat.shape)\n",
    "        \n",
    "        out = tf.squeeze(self.dense_actv(flat))\n",
    "        \n",
    "#         print(out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = Discriminator((32,32), 3)\n",
    "g2 = Generator(10, (32,32), 3)\n",
    "d1.kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "noise_input = tf.random.normal((5, 10))\n",
    "pics2 = g1(tf.expand_dims(noise_input, 0))\n",
    "# plt.imshow(pics2[-1, :, :, 0], cmap='gray')\n",
    "print(pics2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 256), dtype=float32, numpy=\n",
       "array([[-4.2097348e-05,  7.3560682e-04,  4.1931678e-04, ...,\n",
       "        -6.4554793e-04,  3.2143324e-04, -7.3278497e-04],\n",
       "       [ 9.6493168e-05,  6.1062683e-04,  2.7953341e-04, ...,\n",
       "        -2.8354197e-04,  6.7145814e-04, -7.1064540e-04],\n",
       "       [-4.3484080e-05,  9.0144092e-04,  3.7927885e-04, ...,\n",
       "        -5.2655104e-04,  3.4247764e-04, -3.9046450e-04],\n",
       "       [ 1.2035619e-04,  4.8628807e-04,  2.1088176e-04, ...,\n",
       "        -4.7244271e-04,  2.6136174e-04, -5.2813505e-04],\n",
       "       [ 8.6942673e-05,  5.2591704e-04,  2.6754619e-04, ...,\n",
       "        -2.4842605e-04,  1.5544734e-04, -5.4617861e-04]], dtype=float32)>"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deci = d1(pics2)\n",
    "deci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator_118\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " leaky_re_lu_354 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " leaky_re_lu_355 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " leaky_re_lu_356 (LeakyReLU)  multiple                 0         \n",
      "                                                                 \n",
      " flatten_118 (Flatten)       multiple                  0         \n",
      "                                                                 \n",
      " conv2d_354 (Conv2D)         multiple                  1792      \n",
      "                                                                 \n",
      " conv2d_355 (Conv2D)         multiple                  73856     \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         multiple                  295168    \n",
      "                                                                 \n",
      " dense_266 (Dense)           multiple                  1048832   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,419,648\n",
      "Trainable params: 1,419,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CramerDCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class DCGAN:\n",
    "    \n",
    "    def __init__(self, dataset, image_shape, num_channel, noise_latent_dim,\n",
    "                 buffer_size=60000, batch_size=256, lr=3e-4, gp_lam = 10.0):\n",
    "        assert len(image_shape) == 2\n",
    "        assert image_shape[0]%8 == 0\n",
    "        assert image_shape[1]%8 == 0\n",
    "        \n",
    "        self.image_shape = image_shape\n",
    "        self.num_channel = num_channel\n",
    "        self.noise_latent_dim = noise_latent_dim\n",
    "        self.buffer_cap, self.batch_size, self.gp_lam = buffer_size, batch_size, gp_lam\n",
    "        self.num_img_prog_monit = 16\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        # NOTE: Dataset must be processed differently for different source and applications\n",
    "        \n",
    "        self.g = Generator(self.noise_latent_dim, self.image_shape, self.num_channel)\n",
    "        self.d = Discriminator(self.image_shape, self.num_channel)\n",
    "        \n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr)\n",
    "        \n",
    "        self.g_seed = tf.random.normal((self.num_img_prog_monit, self.noise_latent_dim))\n",
    "\n",
    "    def cramer_loss(self, d_x_data, d_g_z_1, d_g_z_2, x_it):\n",
    "        \n",
    "        crit_r = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_x_data**2, axis = 1)+EPSILON))\n",
    "        crit_g_1 = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_g_z_1**2, axis = 1)+EPSILON))\n",
    "        \n",
    "        L_srg = tf.math.add(crit_r, -crit_g_1)\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d(x_it)\n",
    "            crit_it = tf.math.add(tf.math.sqrt(tf.reduce_sum(tf.math.add(d_it, -d_g_z_2)**2, axis = 1)+EPSILON),\n",
    "                   -tf.math.sqrt(tf.reduce_sum(d_it**2, axis = 1)+EPSILON))\n",
    "            \n",
    "        gp_grad = t_gp.gradient(crit_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3])+EPSILON)\n",
    "        \n",
    "        # d_loss\n",
    "        L_d = tf.reduce_mean(-L_srg + (self.gp_lam*((l2n_gp-1.0)**2)))\n",
    "\n",
    "        l2nrg1 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_1)**2, axis = 1)+EPSILON)\n",
    "        l2nrg2 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_x_data, -d_g_z_2)**2, axis = 1)+EPSILON)\n",
    "        l2ng12 = tf.math.sqrt(tf.reduce_sum(tf.math.add(d_g_z_1, -d_g_z_2)**2, axis = 1)+EPSILON)\n",
    "\n",
    "        # g_loss\n",
    "        L_g = tf.reduce_mean(l2nrg1 + l2nrg2 - l2ng12)\n",
    "\n",
    "        return L_g, L_d\n",
    "        \n",
    "    \n",
    "    @tf.function\n",
    "    def update(self, imgs):\n",
    "        noise_input1 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        noise_input2 = tf.random.normal((imgs.shape[0], self.noise_latent_dim))\n",
    "        \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            g_z_1 = self.g(noise_input1)\n",
    "            g_z_2 = self.g(noise_input2)\n",
    "            \n",
    "            d_x_data = self.d(imgs)\n",
    "            d_g_z_1 = self.d(g_z_1)\n",
    "            d_g_z_2 = self.d(g_z_2)\n",
    "            \n",
    "            epsi = tf.random.uniform([imgs.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "            x_it = tf.math.add(epsi*imgs, (1.0-epsi)*g_z_1)\n",
    "            g_loss, d_loss = self.cramer_loss(d_x_data, d_g_z_1, d_g_z_2, x_it)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "        \n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        return g_loss, d_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            for img_b, l_b in self.dataset:\n",
    "                norm_img_b = (img_b-127.5)/127.5\n",
    "                g_l, d_l = self.update(norm_img_b)\n",
    "            print(\"Generator Loss: \", g_l, \", Discriminator Loss: \",  d_l)\n",
    "            \n",
    "            self.monitor_progress(epo)\n",
    "            \n",
    "    def monitor_progress(self, epo):\n",
    "        pics = self.g(self.g_seed)\n",
    "        \n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        for i in range(pics.shape[0]):\n",
    "            plt.subplot(4,4,i+1)\n",
    "            plt.imshow(tf.cast(tf.math.round(pics[i,:,:,:]*127.5+127.5), tf.int32))\n",
    "            plt.axis('off')\n",
    "            \n",
    "#         plt.savefig('/Users/anthonylaw/Desktop/Hustle/GAN-devel/imgs/image_{:04d}.png'.format(epo))\n",
    "        plt.savefig('/home/tony/TO_BE_REMOVED/imgs/image_{:04d}.png'.format(epo))\n",
    "        # NEEDS to be changed for machines\n",
    "        \n",
    "        plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  \"/home/tony/TO_BE_REMOVED/celeba_data/imgs/\",\n",
    "  seed=123,\n",
    "  image_size=(64, 64),\n",
    "  batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan1 = DCGAN(train_ds, (64, 64), 3, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan1.train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
