{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aec4abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d5b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/client'\n",
    "# d2 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/counselor'\n",
    "# # iterate over files in\n",
    "# # that directory\n",
    "\n",
    "# data_in = []\n",
    "# data_out = []\n",
    "# for filename in sorted(os.listdir(d1)):\n",
    "#     fn = os.path.join(d1, filename)\n",
    "#     if os.path.isfile(fn):\n",
    "#         with open(fn) as f:\n",
    "#             lines = f.readlines()\n",
    "#             aline = []\n",
    "#             for x in lines:\n",
    "#                 aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "#             data_in.append(aline)\n",
    "#         f.close()\n",
    "\n",
    "\n",
    "# for filename in sorted(os.listdir(d2)):\n",
    "#     fn = os.path.join(d2, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(fn):\n",
    "#         with open(fn) as f:\n",
    "#             lines = f.readlines()\n",
    "#             aline = []\n",
    "#             for x in lines:\n",
    "#                 aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "#             data_out.append(aline)\n",
    "#         f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3994fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_in = data_in[:len(data_out)]\n",
    "# # print(tf.constant(data_in).shape)\n",
    "# # print(tf.constant(data_out).shape)\n",
    "\n",
    "# data = []\n",
    "# sequence_len = 16\n",
    "# ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "# ds = ds.batch(sequence_len)\n",
    "# ds = ds.shuffle(ds.cardinality().numpy())\n",
    "# for inn, outt in ds:\n",
    "#     print(inn.shape, outt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aad57b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GU(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2, emb_dim=512, gate_filters=32, num_resolutions=3, attn_res_idx=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.num_channels = num_channels\n",
    "        self.num_resolutions = num_resolutions\n",
    "        self.attn_res_idx = attn_res_idx\n",
    "        self.emb_dim = emb_dim\n",
    "        self.gate_filters = gate_filters\n",
    "#         self.model = self.build_graph()\n",
    "        \n",
    "#     def timestep_embedding(self, ts, embedding_dim):\n",
    "#         assert len(ts.shape)==1\n",
    "        \n",
    "#         half_dim = embedding_dim // 2\n",
    "#         emb = -(tf.math.log(10000.0)/(half_dim-1))\n",
    "        \n",
    "#         idxs = tf.range(half_dim, dtype=tf.float32)\n",
    "#         emb = tf.math.exp(idxs*emb)\n",
    "        \n",
    "#         ts = tf.cast(ts, dtype=tf.float32)\n",
    "        \n",
    "#         emb = ts[:,None]* emb[None,:]\n",
    "        \n",
    "#         pe = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
    "        \n",
    "#         return pe\n",
    "    \n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "        \n",
    "    def ResBlK(self, x, temb=None):\n",
    "        h = self.nonlinearity(self.normalize(x))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        if not temb == None:\n",
    "            temb = self.nonlinearity(temb)\n",
    "            h +=  tf.reshape(layers.Dense(h.shape[-1])(temb), (-1, 1, 1,h.shape[-1]))\n",
    "\n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return x+h\n",
    "        \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "\n",
    "    def upsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2DTranspose(filters, (3, 3),\n",
    "                                       strides=(factor, factor), padding='same')(x)\n",
    "        \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def design(self, img_input):\n",
    "        \n",
    "        hs = [layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(img_input)]\n",
    "        \n",
    "        for i in range(self.num_resolutions):\n",
    "            h = self.ResBlK(hs[-1])\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)\n",
    "                \n",
    "            if i != self.num_resolutions - 1:\n",
    "                h = self.downsample(h, h.shape[-1]*2)\n",
    "                \n",
    "            hs.append(h)\n",
    "\n",
    "        h = hs[-1]\n",
    "        h = self.ResBlK(h)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h = self.ResBlK(h)\n",
    "                \n",
    "        for i in reversed(range(self.num_resolutions)):\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)   \n",
    "            h = self.ResBlK(h)\n",
    "            h = h+hs[i]\n",
    "                \n",
    "            if i != 0:\n",
    "                h = self.upsample(h, h.shape[-1]//2)\n",
    "                \n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        \n",
    "        h = layers.Conv2D(self.num_channels, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "#     def call(self, x):\n",
    "#         return self.model([x])\n",
    "    \n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=(self.in_dim[0],\n",
    "                                        self.in_dim[1], self.num_channels))\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.design(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e72f5acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-26 21:37:20.214139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.219129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.219321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.219844: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-26 21:37:20.220258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.220363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.220452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.506145: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.506249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.506326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-26 21:37:20.506396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5746 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "unet1=GU((16, 68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd71dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = unet1.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61008bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8f35410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model1,to_file=\"./imgs/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc71ba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.model_to_dot(model1, show_shapes=True, show_layer_activations=True).write_raw(\"model.dot\")\n",
    "# graph.write_raw(\"output_raw.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88de40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        # self.dum = dum\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc).build_model()\n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def loss_func(self, pred_co, gt_co):\n",
    "        return tf.reduce_mean(tf.math.sqrt(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3])+EPSILON))\n",
    "        \n",
    "    @tf.function\n",
    "    def update(self, cl, co):\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            pred_co = self.g(cl)\n",
    "            g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "        return g_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.stack(batch_inn)\n",
    "                        tf_batch_outt = tf.stack(batch_outt)\n",
    "                        g_losses.append(self.update(tf_batch_inn, tf_batch_outt))\n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \"Generator Avg. Loss: \", np.mean(g_losses), flush=True)\n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7f2b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afcc2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = model(ds_path, (8,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d575cfc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m1.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aea8df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a68e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch_size=32\n",
    "# batch_inn = []\n",
    "# batch_outt = []\n",
    "\n",
    "\n",
    "# for inn, outt in m1.ds:\n",
    "#     if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "#         if (len(batch_inn))%batch_size ==0:\n",
    "#             tf_batch_inn = tf.stack(batch_inn)\n",
    "#             tf_batch_outt = tf.stack(batch_outt)\n",
    "#             if not tf_batch_inn.shape[0] == 0:\n",
    "#                 pred_out = m1.g(tf_batch_inn)\n",
    "#                 print(pred_out.shape)\n",
    "#             batch_inn = []\n",
    "#             batch_outt = []\n",
    "#             batch_inn.append(inn)\n",
    "#             batch_outt.append(outt)\n",
    "#         else:\n",
    "#             batch_inn.append(inn)\n",
    "#             batch_outt.append(outt)\n",
    "#         print(batch_outt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de67e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnD(Model):\n",
    "    \n",
    "    def __init__(self, in_dim ,num_out_filter=1,\n",
    "                  gate_filters=32):\n",
    "#                  stage_filters=(256,256,256,256,256,256,256), stage_kernels=(3,3,3,3,3,3,3), stage_strides_ds=(2,2,2,2,2,2)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # staging params must be equal\n",
    "        # assert len(stage_filters) == len(stage_kernels)\n",
    "        # assert len(stage_filters) == len(stage_strides_ds)+1\n",
    "        \n",
    "        self.gate_filters = gate_filters\n",
    "        self.in_dim = in_dim\n",
    "#         self.attn_shape = attn_shape\n",
    "        self.num_out_filter = num_out_filter\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "    \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "\n",
    "    def design(self, latent):\n",
    "        \n",
    "#         h = layers.Dense(self.attn_shape[0]*self.attn_shape[1]*self.gate_filters)(latent)\n",
    "#         h = layers.Reshape((self.attn_shape[0], self.attn_shape[1], self.gate_filters))(h)\n",
    "        h = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(latent)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(self.num_out_filter)(h)\n",
    "        h = self.nonlinearity(h)\n",
    "    \n",
    "        return h\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.in_dim)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.design(x))\n",
    "\n",
    "    \n",
    "    # def build_graph(self):\n",
    "    #     self.build(input_shape=(None,self.image_shape_in[0],\n",
    "    #                                     self.image_shape_in[1], self.num_channel))\n",
    "        \n",
    "    # def reproduce_model(self):\n",
    "    #     x = layers.Input(shape=(self.image_shape[0],\n",
    "    #                                     self.image_shape[1], self.num_channel))\n",
    "        \n",
    "    #     return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "#     def plot_models(self,path):\n",
    "#         rmodel = self.reproduce_model()\n",
    "#         tf.keras.utils.plot_model(rmodel, to_file=path+\"/model.png\", show_shapes=True, show_layer_activations=True)\n",
    "        \n",
    "#         idx = 0\n",
    "#         for resblk in self.resblks:\n",
    "#             tf.keras.utils.plot_model(resblk.reproduce_model(self.res_inshape[idx], (1,1)), to_file=path+\"/resblk_{:04d}.png\".format(idx), show_shapes=True, show_layer_activations=True)\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e09acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = AttnD([16,68,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bed4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d86d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(d1, to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4d4e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4028407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class gan_model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, dum=5, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4, gp_lam=10.0):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        self.gp_lam = gp_lam\n",
    "        self.dum = dum\n",
    "        self.in_shape = list(self.s)\n",
    "        self.in_shape.append(self.nc)\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc).build_model()\n",
    "        self.d = AttnD(self.in_shape).build_model()\n",
    "\n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def W_loss(self, d_data, d_gen, x_it):\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d(x_it)\n",
    "\n",
    "        gp_grad = t_gp.gradient(d_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3])+EPSILON)\n",
    "        L_gp = self.gp_lam*(l2n_gp-1.0)**2\n",
    "\n",
    "        L_g = d_data - d_gen\n",
    "\n",
    "        L_d = -L_g + L_gp\n",
    "\n",
    "        return tf.nn.compute_average_loss(L_g), tf.nn.compute_average_loss(L_d)\n",
    "    \n",
    "    def loss_func(self, pred_co, gt_co):\n",
    "        return tf.reduce_mean(tf.math.sqrt(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3])+EPSILON))\n",
    "        \n",
    "    # @tf.function\n",
    "    # def update(self, cl, co):\n",
    "    #     with tf.GradientTape() as g_tape:\n",
    "    #         pred_co = self.g(cl)\n",
    "    #         g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "    #     grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "    #     self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "    #     return g_loss\n",
    "    \n",
    "    @tf.function \n",
    "    def update(self, cl, co, update_gen=True):\n",
    "        \n",
    "        # noise_input = tf.random.normal((imgs.shape[0], self.latent_dim))\n",
    "            \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            gco = self.g(cl)\n",
    "\n",
    "            dx = self.d(co)\n",
    "            dg = self.d(gco)\n",
    "\n",
    "            epsi = tf.random.uniform([co.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "            co_it = tf.math.add(epsi*tf.cast(co,tf.float32), (1.0-epsi)*gco)\n",
    "\n",
    "            g_loss, d_loss = self.W_loss(dx, dg, co_it)\n",
    "\n",
    "        if update_gen:\n",
    "            grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "\n",
    "            self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        else:\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "\n",
    "        return g_loss, d_loss\n",
    "\n",
    "    def train(self, epochs=50):\n",
    "        num_training = 0\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            d_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if list(inn.shape) == self.in_shape and list(outt.shape) == self.in_shape:\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.stack(batch_inn)\n",
    "                        tf_batch_outt = tf.stack(batch_outt)\n",
    "                        if num_training%self.dum == 0:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, True)\n",
    "                            g_losses.append(g_l.numpy())\n",
    "                        else:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, False)\n",
    "                        d_losses.append(d_l.numpy())\n",
    "\n",
    "                        num_training = (num_training+1)%self.dum\n",
    "                        \n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \" Generator Avg. Loss: \", np.mean(g_losses),\n",
    "                   \", Discriminator Avg. Loss: \", np.mean(d_losses), flush=True)\n",
    "            \n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93670578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4280d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = gan_model(ds_path, (8,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9505f683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0000  Generator Avg. Loss:  3371113.8 , Discriminator Avg. Loss:  -107966570.0\n",
      "Epoch 0001  Generator Avg. Loss:  3352548.2 , Discriminator Avg. Loss:  -107638320.0\n",
      "Epoch 0002  Generator Avg. Loss:  3352978.5 , Discriminator Avg. Loss:  -107548320.0\n",
      "Epoch 0003  Generator Avg. Loss:  3353870.2 , Discriminator Avg. Loss:  -107264250.0\n",
      "Epoch 0004  Generator Avg. Loss:  3352963.8 , Discriminator Avg. Loss:  -107280424.0\n",
      "Epoch 0005  Generator Avg. Loss:  3348618.0 , Discriminator Avg. Loss:  -107357770.0\n",
      "Epoch 0006  Generator Avg. Loss:  3342575.5 , Discriminator Avg. Loss:  -107152504.0\n",
      "Epoch 0007  Generator Avg. Loss:  3325088.0 , Discriminator Avg. Loss:  -106934136.0\n",
      "Epoch 0008  Generator Avg. Loss:  3334484.0 , Discriminator Avg. Loss:  -106777330.0\n",
      "Epoch 0009  Generator Avg. Loss:  3329871.0 , Discriminator Avg. Loss:  -106654200.0\n",
      "Epoch 0010  Generator Avg. Loss:  3316477.2 , Discriminator Avg. Loss:  -106553384.0\n",
      "Epoch 0011  Generator Avg. Loss:  3312848.0 , Discriminator Avg. Loss:  -106406030.0\n",
      "Epoch 0012  Generator Avg. Loss:  3300615.0 , Discriminator Avg. Loss:  -106232610.0\n",
      "Epoch 0013  Generator Avg. Loss:  3315753.0 , Discriminator Avg. Loss:  -106183630.0\n",
      "Epoch 0014  Generator Avg. Loss:  3312017.8 , Discriminator Avg. Loss:  -106014880.0\n",
      "Epoch 0015  Generator Avg. Loss:  3295303.5 , Discriminator Avg. Loss:  -105820690.0\n",
      "Epoch 0016  Generator Avg. Loss:  3293639.5 , Discriminator Avg. Loss:  -105618920.0\n",
      "Epoch 0017  Generator Avg. Loss:  3292472.0 , Discriminator Avg. Loss:  -105458780.0\n",
      "Epoch 0018  Generator Avg. Loss:  3275624.0 , Discriminator Avg. Loss:  -105273896.0\n",
      "Epoch 0019  Generator Avg. Loss:  3273518.2 , Discriminator Avg. Loss:  -105129370.0\n",
      "Epoch 0020  Generator Avg. Loss:  3276865.8 , Discriminator Avg. Loss:  -104874950.0\n",
      "Epoch 0021  Generator Avg. Loss:  3255646.2 , Discriminator Avg. Loss:  -104679640.0\n",
      "Epoch 0022  Generator Avg. Loss:  3272271.5 , Discriminator Avg. Loss:  -104689980.0\n",
      "Epoch 0023  Generator Avg. Loss:  3244726.2 , Discriminator Avg. Loss:  -104295040.0\n",
      "Epoch 0024  Generator Avg. Loss:  3247688.5 , Discriminator Avg. Loss:  -104288360.0\n",
      "Epoch 0025  Generator Avg. Loss:  3248252.5 , Discriminator Avg. Loss:  -104207730.0\n",
      "Epoch 0026  Generator Avg. Loss:  3255178.8 , Discriminator Avg. Loss:  -104129750.0\n",
      "Epoch 0027  Generator Avg. Loss:  3239303.5 , Discriminator Avg. Loss:  -103828790.0\n",
      "Epoch 0028  Generator Avg. Loss:  3232784.5 , Discriminator Avg. Loss:  -103729850.0\n",
      "Epoch 0029  Generator Avg. Loss:  3221368.2 , Discriminator Avg. Loss:  -103440570.0\n",
      "Epoch 0030  Generator Avg. Loss:  3228247.5 , Discriminator Avg. Loss:  -103439176.0\n",
      "Epoch 0031  Generator Avg. Loss:  3214465.5 , Discriminator Avg. Loss:  -103078250.0\n",
      "Epoch 0032  Generator Avg. Loss:  3207237.5 , Discriminator Avg. Loss:  -102945320.0\n",
      "Epoch 0033  Generator Avg. Loss:  3200515.8 , Discriminator Avg. Loss:  -102697590.0\n",
      "Epoch 0034  Generator Avg. Loss:  3206048.2 , Discriminator Avg. Loss:  -102551910.0\n",
      "Epoch 0035  Generator Avg. Loss:  3188013.5 , Discriminator Avg. Loss:  -102491864.0\n",
      "Epoch 0036  Generator Avg. Loss:  3191838.2 , Discriminator Avg. Loss:  -102238040.0\n",
      "Epoch 0037  Generator Avg. Loss:  3180215.5 , Discriminator Avg. Loss:  -102187490.0\n",
      "Epoch 0038  Generator Avg. Loss:  3167067.8 , Discriminator Avg. Loss:  -101795944.0\n",
      "Epoch 0039  Generator Avg. Loss:  3173392.0 , Discriminator Avg. Loss:  -101642680.0\n",
      "Epoch 0040  Generator Avg. Loss:  3158595.5 , Discriminator Avg. Loss:  -101460020.0\n",
      "Epoch 0041  Generator Avg. Loss:  3162101.5 , Discriminator Avg. Loss:  -101191070.0\n",
      "Epoch 0042  Generator Avg. Loss:  3147580.0 , Discriminator Avg. Loss:  -101099780.0\n",
      "Epoch 0043  Generator Avg. Loss:  3149479.5 , Discriminator Avg. Loss:  -100902000.0\n",
      "Epoch 0044  Generator Avg. Loss:  3143049.5 , Discriminator Avg. Loss:  -100799080.0\n",
      "Epoch 0045  Generator Avg. Loss:  3136985.2 , Discriminator Avg. Loss:  -100492330.0\n",
      "Epoch 0046  Generator Avg. Loss:  3131312.0 , Discriminator Avg. Loss:  -100371840.0\n",
      "Epoch 0047  Generator Avg. Loss:  3114216.2 , Discriminator Avg. Loss:  -100045150.0\n",
      "Epoch 0048  Generator Avg. Loss:  3120428.2 , Discriminator Avg. Loss:  -99910390.0\n",
      "Epoch 0049  Generator Avg. Loss:  3101114.8 , Discriminator Avg. Loss:  -99488340.0\n"
     ]
    }
   ],
   "source": [
    "gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1bb42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Avg. Loss:  7899.4136\n"
     ]
    }
   ],
   "source": [
    "gan.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a4fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2SAttn(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "\n",
    "    def call(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca529a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2SAttn_M(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2):\n",
    "        super().__init__()\n",
    "        # self.l2sattn1 = L2SAttn()\n",
    "        self.in_dim = in_dim\n",
    "        self.nc = num_channels\n",
    "        self.s = list(in_dim)\n",
    "        self.s.append(self.nc)\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def call(self, x):\n",
    "        h = self.normalize(x)\n",
    "        Q = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        K = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        dK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2]*K.shape[3], tf.float32))\n",
    "        V = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        # phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        Q = tf.reshape(Q, shape=(-1, Q.shape[1]*Q.shape[2], Q.shape[3]))\n",
    "\n",
    "        K = tf.reshape(K, shape=(-1, K.shape[1]*K.shape[2], K.shape[3]))\n",
    "        V = tf.reshape(V, shape=(-1, V.shape[1]*V.shape[2], V.shape[3]))\n",
    "        \n",
    "        rnQ = tf.math.square(tf.math.reduce_euclidean_norm(Q, axis=-1, keepdims=True))\n",
    "        f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "        f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        rnK = tf.math.square(tf.math.reduce_euclidean_norm(K, axis=-1, keepdims=True))\n",
    "        f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "        f = (f1-2*f2+f3)/dK\n",
    "        \n",
    "        f = layers.Softmax()(-f)\n",
    "        \n",
    "        y = tf.matmul(f, V)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.nc))\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.s)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4630d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = L2SAttn_M((32,32), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1dd5c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e5a8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(a.build_model(),to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "102d1b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 64, 64]), TensorShape([2, 64, 64]), TensorShape([2, 64, 64]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = tf.random.uniform(shape=(2, 64, 32))\n",
    "K = tf.random.uniform(shape=(2, 64, 32))\n",
    "\n",
    "rnQ = tf.math.square(tf.math.reduce_euclidean_norm(Q, axis=-1, keepdims=True))\n",
    "f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "rnK = tf.math.square(tf.math.reduce_euclidean_norm(K, axis=-1, keepdims=True))\n",
    "f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "f1.shape, f2.shape, f3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28fb3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.ones(shape=(None,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69331b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
