{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2170d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf tensorflow==2.11.0\n",
    "# !pip uninstall tensorrt -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958bae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efe8e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b7c76",
   "metadata": {},
   "source": [
    "## File Parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/client'\n",
    "d2 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/counselor'\n",
    "# iterate over files in\n",
    "# that directory\n",
    "\n",
    "data_in = []\n",
    "data_out = []\n",
    "for filename in sorted(os.listdir(d1)):\n",
    "    fn = os.path.join(d1, filename)\n",
    "    if os.path.isfile(fn):\n",
    "        with open(fn) as f:\n",
    "            lines = f.readlines()\n",
    "            aline = []\n",
    "            for x in lines:\n",
    "                # print(x.rstrip('\\n').split(\" \")[1:5])\n",
    "                x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                x_low = int(x_low[2:len(x_low)-1])\n",
    "                y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                y_low = int(y_low[0:len(y_low)-1])\n",
    "                x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                x_high = int(x_high[1:len(x_high)-1])\n",
    "                y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                y_high = int(y_high[0:len(y_high)-2])\n",
    "                norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                aline.append([norm_x, norm_x])\n",
    "            data_in.append(aline)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "for filename in sorted(os.listdir(d2)):\n",
    "    fn = os.path.join(d2, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(fn):\n",
    "        with open(fn) as f:\n",
    "            lines = f.readlines()\n",
    "            aline = []\n",
    "            for x in lines:\n",
    "                x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                x_low = int(x_low[2:len(x_low)-1])\n",
    "                y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                y_low = int(y_low[0:len(y_low)-1])\n",
    "                x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                x_high = int(x_high[1:len(x_high)-1])\n",
    "                y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                y_high = int(y_high[0:len(y_high)-2])\n",
    "                norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                aline.append([norm_x, norm_x])\n",
    "            data_out.append(aline)\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3994fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_in = data_in[:len(data_out)]\n",
    "# # print(tf.constant(data_in).shape)\n",
    "# # print(tf.constant(data_out).shape)\n",
    "\n",
    "# data = []\n",
    "# sequence_len = 16\n",
    "# ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "# ds = ds.batch(sequence_len)\n",
    "# ds = ds.shuffle(ds.cardinality().numpy())\n",
    "# for inn, outt in ds:\n",
    "#     print(inn.shape, outt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b035ca",
   "metadata": {},
   "source": [
    "## U-Net Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad57b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GU(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2, emb_dim=512, gate_filters=32, num_resolutions=3, attn_res_idx=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.num_channels = num_channels\n",
    "        self.num_resolutions = num_resolutions\n",
    "        self.attn_res_idx = attn_res_idx\n",
    "        self.emb_dim = emb_dim\n",
    "        self.gate_filters = gate_filters\n",
    "#         self.model = self.build_graph()\n",
    "        \n",
    "#     def timestep_embedding(self, ts, embedding_dim):\n",
    "#         assert len(ts.shape)==1\n",
    "        \n",
    "#         half_dim = embedding_dim // 2\n",
    "#         emb = -(tf.math.log(10000.0)/(half_dim-1))\n",
    "        \n",
    "#         idxs = tf.range(half_dim, dtype=tf.float32)\n",
    "#         emb = tf.math.exp(idxs*emb)\n",
    "        \n",
    "#         ts = tf.cast(ts, dtype=tf.float32)\n",
    "        \n",
    "#         emb = ts[:,None]* emb[None,:]\n",
    "        \n",
    "#         pe = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
    "        \n",
    "#         return pe\n",
    "    \n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "        \n",
    "    def ResBlK(self, x, temb=None):\n",
    "        h = self.nonlinearity(self.normalize(x))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        if not temb == None:\n",
    "            temb = self.nonlinearity(temb)\n",
    "            h +=  tf.reshape(layers.Dense(h.shape[-1])(temb), (-1, 1, 1,h.shape[-1]))\n",
    "\n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return x+h\n",
    "        \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "\n",
    "    def upsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2DTranspose(filters, (3, 3),\n",
    "                                       strides=(factor, factor), padding='same')(x)\n",
    "        \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        W_QK = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')\n",
    "        Q = W_QK(x)\n",
    "        K = W_QK(x)\n",
    "        \n",
    "        srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2]*K.shape[3], tf.float32))\n",
    "        V = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        # phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        Q = tf.reshape(Q, shape=(-1, Q.shape[1]*Q.shape[2], Q.shape[3]))\n",
    "\n",
    "        K = tf.reshape(K, shape=(-1, K.shape[1]*K.shape[2], K.shape[3]))\n",
    "        V = tf.reshape(V, shape=(-1, V.shape[1]*V.shape[2], V.shape[3]))\n",
    "        \n",
    "        rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "        f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "        f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "        f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "        f = (f1-2*f2+f3)/srdK\n",
    "        \n",
    "        f = layers.Softmax()(-f)\n",
    "        \n",
    "        y = tf.matmul(f, V)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def call(self, img_input):\n",
    "        \n",
    "        hs = [layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(img_input)]\n",
    "        \n",
    "        for i in range(self.num_resolutions):\n",
    "            h = self.ResBlK(hs[-1])\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)\n",
    "                \n",
    "            if i != self.num_resolutions - 1:\n",
    "                h = self.downsample(h, h.shape[-1]*2)\n",
    "                \n",
    "            hs.append(h)\n",
    "\n",
    "        h = hs[-1]\n",
    "        h = self.ResBlK(h)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h = self.ResBlK(h)\n",
    "                \n",
    "        for i in reversed(range(self.num_resolutions)):\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)   \n",
    "            h = self.ResBlK(h)\n",
    "            h = h+hs[i]\n",
    "                \n",
    "            if i != 0:\n",
    "                h = self.upsample(h, h.shape[-1]//2)\n",
    "                \n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        \n",
    "        h = layers.Conv2D(self.num_channels, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "#     def call(self, x):\n",
    "#         return self.model([x])\n",
    "    \n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=(self.in_dim[0],\n",
    "                                        self.in_dim[1], self.num_channels))\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.num_channels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet1=GU((16, 68))\n",
    "# unet1.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd71dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = unet1.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61008bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f35410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model1,to_file=\"./imgs/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc71ba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.model_to_dot(model1, show_shapes=True, show_layer_activations=True).write_raw(\"model.dot\")\n",
    "# graph.write_raw(\"output_raw.dot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7c7fd",
   "metadata": {},
   "source": [
    "## Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88de40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        # self.dum = dum\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc).build_model()\n",
    "        \n",
    "        ### Optimizer setups ###\n",
    "        \n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr,beta_1=0., weight_decay=0.01)\n",
    "        \n",
    "        ### Optimizer setups ###\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        # print(x.rstrip('\\n').split(\" \")[1:5])\n",
    "                        x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                        x_low = int(x_low[2:len(x_low)-1])\n",
    "                        y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                        y_low = int(y_low[0:len(y_low)-1])\n",
    "                        x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                        x_high = int(x_high[1:len(x_high)-1])\n",
    "                        y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                        y_high = int(y_high[0:len(y_high)-2])\n",
    "                        norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                        norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                        aline.append([norm_x, norm_x])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                        x_low = int(x_low[2:len(x_low)-1])\n",
    "                        y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                        y_low = int(y_low[0:len(y_low)-1])\n",
    "                        x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                        x_high = int(x_high[1:len(x_high)-1])\n",
    "                        y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                        y_high = int(y_high[0:len(y_high)-2])\n",
    "                        norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                        norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                        aline.append([norm_x, norm_x])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def loss_func(self, pred_co, gt_co):\n",
    "        return tf.nn.compute_average_loss(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3]))\n",
    "        \n",
    "    @tf.function\n",
    "    def update(self, cl, co):\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            pred_co = self.g(cl)\n",
    "            g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "        return g_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.cast(tf.stack(batch_inn), dtype=tf.float32)\n",
    "                        tf_batch_outt = tf.cast(tf.stack(batch_outt), dtype=tf.float32)\n",
    "                        g_losses.append(self.update(tf_batch_inn, tf_batch_outt))\n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \"Generator Avg. Loss: \", np.mean(g_losses), flush=True)\n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f2b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = model(ds_path, (8,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575cfc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m1.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de77ad7",
   "metadata": {},
   "source": [
    "## Attention Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de67e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnD(Model):\n",
    "    \n",
    "    def __init__(self, in_dim ,num_out_filter=1,\n",
    "                  gate_filters=32):\n",
    "#                  stage_filters=(256,256,256,256,256,256,256), stage_kernels=(3,3,3,3,3,3,3), stage_strides_ds=(2,2,2,2,2,2)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # staging params must be equal\n",
    "        # assert len(stage_filters) == len(stage_kernels)\n",
    "        # assert len(stage_filters) == len(stage_strides_ds)+1\n",
    "        \n",
    "        self.gate_filters = gate_filters\n",
    "        self.in_dim = in_dim\n",
    "#         self.attn_shape = attn_shape\n",
    "        self.num_out_filter = num_out_filter\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "    \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = x\n",
    "        \n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdphi = tf.math.sqrt(tf.cast(phi.shape[1]*phi.shape[2]*phi.shape[3], tf.float32))\n",
    "        \n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)/srdphi\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        z = self.normalize(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def call(self, latent):\n",
    "        \n",
    "#         h = layers.Dense(self.attn_shape[0]*self.attn_shape[1]*self.gate_filters)(latent)\n",
    "#         h = layers.Reshape((self.attn_shape[0], self.attn_shape[1], self.gate_filters))(h)\n",
    "        h = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(latent)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(self.num_out_filter)(h)\n",
    "        h = self.nonlinearity(h)\n",
    "    \n",
    "        return h\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.in_dim)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.in_dim[2]))\n",
    "        \n",
    "    # def reproduce_model(self):\n",
    "    #     x = layers.Input(shape=(self.image_shape[0],\n",
    "    #                                     self.image_shape[1], self.num_channel))\n",
    "        \n",
    "    #     return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "#     def plot_models(self,path):\n",
    "#         rmodel = self.reproduce_model()\n",
    "#         tf.keras.utils.plot_model(rmodel, to_file=path+\"/model.png\", show_shapes=True, show_layer_activations=True)\n",
    "        \n",
    "#         idx = 0\n",
    "#         for resblk in self.resblks:\n",
    "#             tf.keras.utils.plot_model(resblk.reproduce_model(self.res_inshape[idx], (1,1)), to_file=path+\"/resblk_{:04d}.png\".format(idx), show_shapes=True, show_layer_activations=True)\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0564bfe0",
   "metadata": {},
   "source": [
    "## L2 Attention Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e969e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2AttnD(Model):\n",
    "    \n",
    "    def __init__(self, in_dim ,num_out_filter=1,\n",
    "                  gate_filters=32):\n",
    "#                  stage_filters=(256,256,256,256,256,256,256), stage_kernels=(3,3,3,3,3,3,3), stage_strides_ds=(2,2,2,2,2,2)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # staging params must be equal\n",
    "        # assert len(stage_filters) == len(stage_kernels)\n",
    "        # assert len(stage_filters) == len(stage_strides_ds)+1\n",
    "        \n",
    "        self.gate_filters = gate_filters\n",
    "        self.in_dim = in_dim\n",
    "#         self.attn_shape = attn_shape\n",
    "        self.num_out_filter = num_out_filter\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "    \n",
    "    def NonlocalGaussian(self, x_in, y_in):\n",
    "        hx = x_in\n",
    "        hy = y_in\n",
    "        W_QK = layers.Conv2D(hx.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')\n",
    "        Q = W_QK(hx)\n",
    "        K = W_QK(hy)\n",
    "        \n",
    "        srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2]*K.shape[3], tf.float32))\n",
    "        V = layers.Conv2D(hx.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(hy)\n",
    "        # phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        Q = tf.reshape(Q, shape=(-1, Q.shape[1]*Q.shape[2], Q.shape[3]))\n",
    "\n",
    "        K = tf.reshape(K, shape=(-1, K.shape[1]*K.shape[2], K.shape[3]))\n",
    "        V = tf.reshape(V, shape=(-1, V.shape[1]*V.shape[2], V.shape[3]))\n",
    "        \n",
    "        rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "        f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "        f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "        f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "        f = (f1-2*f2+f3)/srdK\n",
    "        \n",
    "        f = layers.Softmax()(-f)\n",
    "        \n",
    "        y = tf.matmul(f, V)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, hx.shape[1], hx.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x_in, layers.Conv2D(hx.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        z = self.normalize(z)\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def call(self, xy):\n",
    "        \n",
    "        x, y = xy\n",
    "#         h = layers.Dense(self.attn_shape[0]*self.attn_shape[1]*self.gate_filters)(latent)\n",
    "#         h = layers.Reshape((self.attn_shape[0], self.attn_shape[1], self.gate_filters))(h)\n",
    "        hx = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(x)\n",
    "        hy = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                            strides=(1, 1), padding='same')(y)\n",
    "        hx = self.NonlocalGaussian(hx, hx)\n",
    "        hy = self.NonlocalGaussian(hy, hy)\n",
    "        hx = self.downsample(hx,int(self.gate_filters*2.))\n",
    "        hy = self.downsample(hy,int(self.gate_filters*2.))\n",
    "        h = self.NonlocalGaussian(hx, hy)\n",
    "        h = self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(self.num_out_filter)(h)\n",
    "        h = self.nonlinearity(h)\n",
    "    \n",
    "        return h\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.in_dim)\n",
    "        y = layers.Input(shape=self.in_dim)\n",
    "        \n",
    "        return Model(inputs=[x,y], outputs=self.call([x,y]))\n",
    "\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=[(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.in_dim[2]),(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.in_dim[2])])\n",
    "        \n",
    "    # def reproduce_model(self):\n",
    "    #     x = layers.Input(shape=(self.image_shape[0],\n",
    "    #                                     self.image_shape[1], self.num_channel))\n",
    "        \n",
    "    #     return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "#     def plot_models(self,path):\n",
    "#         rmodel = self.reproduce_model()\n",
    "#         tf.keras.utils.plot_model(rmodel, to_file=path+\"/model.png\", show_shapes=True, show_layer_activations=True)\n",
    "        \n",
    "#         idx = 0\n",
    "#         for resblk in self.resblks:\n",
    "#             tf.keras.utils.plot_model(resblk.reproduce_model(self.res_inshape[idx], (1,1)), to_file=path+\"/resblk_{:04d}.png\".format(idx), show_shapes=True, show_layer_activations=True)\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = L2AttnD([16,68,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(d1, to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d4e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c907e996",
   "metadata": {},
   "source": [
    "## GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4028407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class gan_model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, dum=5, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4, gp_lam=10.0):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        self.gp_lam = gp_lam\n",
    "        self.dum = dum\n",
    "        self.in_shape = list(self.s)\n",
    "        self.in_shape.append(self.nc)\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc).build_model()\n",
    "        self.d = L2AttnD(self.in_shape).build_model()\n",
    "\n",
    "        \n",
    "        ### Optimizer setups ###\n",
    "        \n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr,beta_1=0., weight_decay=0.01, global_clipnorm=True)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr,beta_1=0., weight_decay=0.01, global_clipnorm=True)\n",
    "        \n",
    "        ### Optimizer setups ###\n",
    "\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        # print(x.rstrip('\\n').split(\" \")[1:5])\n",
    "                        x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                        x_low = int(x_low[2:len(x_low)-1])\n",
    "                        y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                        y_low = int(y_low[0:len(y_low)-1])\n",
    "                        x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                        x_high = int(x_high[1:len(x_high)-1])\n",
    "                        y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                        y_high = int(y_high[0:len(y_high)-2])\n",
    "                        norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                        norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                        aline.append([norm_x, norm_x])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        x_low = x.rstrip('\\n').split(\" \")[1]\n",
    "                        x_low = int(x_low[2:len(x_low)-1])\n",
    "                        y_low = x.rstrip('\\n').split(\" \")[2]\n",
    "                        y_low = int(y_low[0:len(y_low)-1])\n",
    "                        x_high = x.rstrip('\\n').split(\" \")[3]\n",
    "                        x_high = int(x_high[1:len(x_high)-1])\n",
    "                        y_high = x.rstrip('\\n').split(\" \")[4]\n",
    "                        y_high = int(y_high[0:len(y_high)-2])\n",
    "                        norm_x = (int(x.rstrip('\\n').split(\" \")[-2])-x_low)/(x_high-x_low)\n",
    "                        norm_y = (int(x.rstrip('\\n').split(\" \")[-1])-y_low)/(y_high-y_low)\n",
    "                        aline.append([norm_x, norm_x])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def W_loss(self, d_data, d_gen, cl, x_it):\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d([cl,x_it])\n",
    "\n",
    "        gp_grad = t_gp.gradient(d_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3])+EPSILON)\n",
    "        L_gp = tf.expand_dims(self.gp_lam*(l2n_gp-1.0)**2, -1)\n",
    "\n",
    "        L_g = d_data - d_gen\n",
    "\n",
    "        L_d = -L_g + L_gp\n",
    "        \n",
    "        return tf.nn.compute_average_loss(L_g), tf.nn.compute_average_loss(L_d)\n",
    "    \n",
    "    def loss_func(self, pred_co, gt_co):\n",
    "        print(tf.reduce_mean(pred_co), tf.reduce_mean(gt_co))\n",
    "        return tf.reduce_mean(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3]))\n",
    "        \n",
    "    # @tf.function\n",
    "    # def update(self, cl, co):\n",
    "    #     with tf.GradientTape() as g_tape:\n",
    "    #         pred_co = self.g(cl)\n",
    "    #         g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "    #     grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "    #     self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "    #     return g_loss\n",
    "    \n",
    "    @tf.function\n",
    "    def update(self, cl, co, update_gen=True):\n",
    "        \n",
    "        # noise_input = tf.random.normal((imgs.shape[0], self.latent_dim))\n",
    "            \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            gco = self.g(cl)\n",
    "\n",
    "            dx = self.d([cl,co])\n",
    "            dg = self.d([cl,gco])\n",
    "\n",
    "            epsi = tf.random.uniform([co.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "            co_it = tf.math.add(epsi*tf.cast(co,tf.float32), (1.0-epsi)*gco)\n",
    "\n",
    "            g_loss, d_loss = self.W_loss(dx, dg, cl, co_it)\n",
    "\n",
    "        if update_gen:\n",
    "            grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "\n",
    "            self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        else:\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "\n",
    "        return g_loss, d_loss\n",
    "\n",
    "    def train(self, epochs=50):\n",
    "        num_training = 0\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            d_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if list(inn.shape) == self.in_shape and list(outt.shape) == self.in_shape:\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.stack(batch_inn)\n",
    "                        tf_batch_outt = tf.stack(batch_outt)\n",
    "                        if num_training%self.dum == 0:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, True)\n",
    "                            g_losses.append(g_l.numpy())\n",
    "                        else:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, False)\n",
    "                        d_losses.append(d_l.numpy())\n",
    "\n",
    "                        num_training = (num_training+1)%self.dum\n",
    "                        \n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \" Generator Avg. Loss: \", np.mean(g_losses),\n",
    "                   \", Discriminator Avg. Loss: \", np.mean(d_losses), flush=True)\n",
    "            \n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(errors)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93670578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan = gan_model(ds_path, (16,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.train(epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class L2SAttn(layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def nonlinearity(self, x):\n",
    "#         return tf.keras.activations.swish(x)\n",
    "    \n",
    "#     def normalize(self, x):\n",
    "#         return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         h = self.normalize(x)\n",
    "#         theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "#         theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "#         phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "#         g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "#         f = tf.matmul(theta, phi)\n",
    "        \n",
    "#         f = layers.Softmax()(f)\n",
    "        \n",
    "#         y = tf.matmul(f, g)\n",
    "        \n",
    "#         y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "#         z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(y))\n",
    "#         return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca529a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2SAttn_M(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2):\n",
    "        super().__init__()\n",
    "        # self.l2sattn1 = L2SAttn()\n",
    "        self.in_dim = in_dim\n",
    "        self.nc = num_channels\n",
    "        self.s = list(in_dim)\n",
    "        self.s.append(self.nc)\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def call(self, x):\n",
    "        h = self.normalize(x)\n",
    "        Q = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        K = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2]*K.shape[3], tf.float32))\n",
    "        V = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        # phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        Q = tf.reshape(Q, shape=(-1, Q.shape[1]*Q.shape[2], Q.shape[3]))\n",
    "\n",
    "        K = tf.reshape(K, shape=(-1, K.shape[1]*K.shape[2], K.shape[3]))\n",
    "        V = tf.reshape(V, shape=(-1, V.shape[1]*V.shape[2], V.shape[3]))\n",
    "        \n",
    "        rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "        f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "        f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "        f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "        f = (f1-2*f2+f3)/srdK\n",
    "        \n",
    "        f = layers.Softmax()(-f)\n",
    "        \n",
    "        y = tf.matmul(f, V)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.nc))\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.s)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = L2SAttn_M((32,32), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd5c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(a.build_model(),to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = tf.random.uniform(shape=(2, 64, 32))\n",
    "K = tf.random.uniform(shape=(2, 64, 32))\n",
    "\n",
    "rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2], tf.float32))\n",
    "# srdK\n",
    "# f1, f2, f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.ones(shape=(None,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5b13f",
   "metadata": {},
   "source": [
    "## AffectNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valence_path=\"/home/data_backup/Downloads/affectnet_8labels/train_set/valence_sorted\"\n",
    "train_arousal_path=\"/home/data_backup/Downloads/affectnet_8labels/train_set/arousal_sorted\"\n",
    "train_landmark_path=\"/home/data_backup/Downloads/affectnet_8labels/train_set/landmarks_sorted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf2db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for filename in sorted(os.listdir(train_valence_path)):\n",
    "    fn = os.path.join(train_valence_path, filename)\n",
    "    if os.path.isfile(fn):\n",
    "        val = np.load(fn)\n",
    "        vals.append(float(val))\n",
    "        \n",
    "aros = []\n",
    "for filename in sorted(os.listdir(train_arousal_path)):\n",
    "    fn = os.path.join(train_arousal_path, filename)\n",
    "    if os.path.isfile(fn):\n",
    "        aro = np.load(fn)\n",
    "        aros.append(float(aro))\n",
    "\n",
    "valaros = list(zip(vals, aros))\n",
    "\n",
    "lnds = []\n",
    "for filename in sorted(os.listdir(train_landmark_path)):\n",
    "    fn = os.path.join(train_landmark_path, filename)\n",
    "    if os.path.isfile(fn):\n",
    "        lnd = np.load(fn)\n",
    "        clnd = []\n",
    "        for i in range(len(lnd)):\n",
    "            clnd.append(float(lnd[i])/224.)\n",
    "        lnds.append(clnd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_emo_map = {0:'happy', 1:'angry', 2:'sad', 3:'calm'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668c10bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = []\n",
    "for val, aro in valaros:\n",
    "    if val >= 0 and aro >= 0:\n",
    "        cls.append([1,0,0,0])\n",
    "    if val < 0 and aro >= 0:\n",
    "        cls.append([0,1,0,0])\n",
    "    if val >= 0 and aro < 0:\n",
    "        cls.append([0,0,0,1])\n",
    "    if val < 0 and aro < 0:\n",
    "        cls.append([0,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee58cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cls), len(valaros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908fb2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "ds = tf.data.Dataset.from_tensor_slices((lnds, cls))\n",
    "ds = ds.shuffle(ds.cardinality().numpy())\n",
    "ds = ds.batch(batch_size)\n",
    "ds = ds.repeat(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4632631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapoint_test = None\n",
    "for x,y in ds.take(1):\n",
    "    print(x.shape)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4013b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = tf.matmul(tf.expand_dims(datapoint_test, axis=-1), tf.expand_dims(datapoint_test, axis=-1), transpose_b=True)\n",
    "\n",
    "# y = tf.squeeze(tf.matmul(f, tf.expand_dims(datapoint_test, axis=-1)))\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73154a",
   "metadata": {},
   "source": [
    "### Architecture Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21789962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPadding2D(layers.Layer):\n",
    "    \"\"\"Implements Reflection Padding as a layer.\n",
    "\n",
    "    Args:\n",
    "        padding(tuple): Amount of padding for the\n",
    "        spatial dimensions.\n",
    "\n",
    "    Returns:\n",
    "        A padded tensor with the same type as the input tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, padding=(1, 1), **kwargs):\n",
    "        self.padding = tuple(padding)\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_tensor, mask=None):\n",
    "        padding_width, padding_height = self.padding\n",
    "        padding_tensor = [\n",
    "            [0, 0],\n",
    "            [padding_height, padding_height],\n",
    "            [padding_width, padding_width],\n",
    "            [0, 0],\n",
    "        ]\n",
    "        return tf.pad(input_tensor, padding_tensor, mode=\"REFLECT\")\n",
    "\n",
    "def NonlocalGaussian_1D(x_in):\n",
    "    \n",
    "    hx = x_in\n",
    "    \n",
    "    W_Q = layers.Dense(hx.shape[-1]/2.0)\n",
    "    W_K = layers.Dense(hx.shape[-1]/2.0)\n",
    "    \n",
    "    Q = W_Q(hx)\n",
    "    K = W_K(hx)\n",
    "\n",
    "    srdK = tf.math.sqrt(tf.cast(K.shape[-1], tf.float32))\n",
    "    \n",
    "    V = layers.Dense(hx.shape[-1]/2.0)(hx)\n",
    "\n",
    "    f = tf.matmul(tf.expand_dims(Q, axis=-1), tf.expand_dims(K, axis=-1), transpose_b=True)\n",
    "\n",
    "    f = layers.Softmax()(f)\n",
    "    \n",
    "#     y = tf.squeeze(tf.matmul(f, tf.expand_dims(V, axis=-1)))\n",
    "    y = tf.matmul(f, tf.expand_dims(V, axis=-1))\n",
    "#     y = tf.reshape(y, (-1, hx.shape[1], hx.shape[2], y.shape[-1]))\n",
    "\n",
    "    z = tf.math.add(x_in, layers.Dense(hx.shape[-1])(tf.squeeze(y, axis=-1)))\n",
    "\n",
    "    return z\n",
    "\n",
    "def swish(x):\n",
    "    return tf.keras.activations.swish(x)\n",
    "\n",
    "def insnorm(x):\n",
    "    return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "\n",
    "\n",
    "def pre_act_resblk(x, act_func, norm_func, kernel_size=(3, 3), strides=(1, 1), padding=\"valid\", temb=None):\n",
    "    h = ReflectionPadding2D()(x)\n",
    "    h = act_func(norm_func(h))\n",
    "    h = layers.Conv2D(x.shape[-1], kernel_size,\n",
    "                                    strides=strides, padding=padding)(h)\n",
    "    if not temb == None:\n",
    "        temb = act_func(temb)\n",
    "        h +=  tf.reshape(layers.Dense(h.shape[-1])(temb), (-1, 1, 1,h.shape[-1]))\n",
    "        \n",
    "    h = ReflectionPadding2D()(h)\n",
    "    h = act_func(norm_func(h))\n",
    "    h = layers.Conv2D(x.shape[-1], kernel_size,\n",
    "                                    strides=strides, padding=padding)(h)\n",
    "    \n",
    "    return x+h\n",
    "\n",
    "\n",
    "def downsample(x, filters, kernel_size=(3, 3), padding=\"same\", factor=2):\n",
    "    return layers.Conv2D(filters, kernel_size,\n",
    "                                    strides=(factor, factor), padding=padding)(x)\n",
    "\n",
    "def upsample(x, filters, kernel_size=(3, 3), padding=\"same\", factor=2):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size,\n",
    "                                    strides=(factor, factor), padding=padding)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fdb7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=(136,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e4ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifier1(\n",
    "    act_func, \n",
    "    filters=64,\n",
    "    num_attn_blocks=1\n",
    "):\n",
    "    lnd_input = layers.Input(shape=input_size)\n",
    "    x = layers.Dense(filters)(lnd_input)\n",
    "\n",
    "    x = act_func(x)\n",
    "\n",
    "    # Attention blocks\n",
    "    for _ in range(num_attn_blocks):\n",
    "\n",
    "        x = NonlocalGaussian_1D(x)\n",
    "\n",
    "    x = layers.Dense(4)(x)\n",
    "\n",
    "    model = Model(inputs=lnd_input, outputs=x)\n",
    "    return model\n",
    "\n",
    "def get_classifier2(\n",
    "    act_func, \n",
    "    filters=64\n",
    "):\n",
    "    lnd_input = layers.Input(shape=input_size)\n",
    "    x = layers.Dense(filters)(lnd_input)\n",
    "\n",
    "    x = act_func(x)\n",
    "\n",
    "#     # Attention blocks\n",
    "#     for _ in range(num_attn_blocks):\n",
    "\n",
    "#         x = NonlocalGaussian_1D(x)\n",
    "\n",
    "    x = layers.Dense(4)(x)\n",
    "\n",
    "    model = Model(inputs=lnd_input, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adffa99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_F = get_classifier1(swish,filters=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ecdc78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(classi_F, to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb8a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_F.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f6745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BiCE(d_real, d_fake):\n",
    "#         d_real = tf.math.sigmoid(d_real)\n",
    "#         d_fake = tf.math.sigmoid(d_fake)\n",
    "#         return tf.nn.compute_average_loss(tf.reduce_mean((-d_real*tf.math.log(tf.clip_by_value(d_fake,\n",
    "#                             1e-16, 1)) - (1.0 - d_real)*tf.math.log(\n",
    "#                             tf.clip_by_value(1.0 - d_fake,\n",
    "#                             1e-16, 1))),\n",
    "#                             axis=-1))\n",
    "\n",
    "\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(\n",
    "    from_logits=True)\n",
    "\n",
    "def L2(pred, y):\n",
    "        return tf.reduce_mean(tf.norm(pred-y, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adafa4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.random.normal((64,68))\n",
    "b = tf.random.normal((64,68))\n",
    "\n",
    "L2(a, b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab14ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValaroModel1(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        classifer_F,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.classifer_F = classifer_F\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        classifer_F_optimizer,\n",
    "        classifier_loss_fn,\n",
    "    ):\n",
    "        super().compile()\n",
    "        self.classifer_F_optimizer = classifer_F_optimizer\n",
    "        self.classifier_loss_fn = classifier_loss_fn\n",
    "\n",
    "\n",
    "    def train_step(self, batch_data):\n",
    "        lnd, valaro = batch_data\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            pred = self.classifer_F(lnd, training=True)\n",
    "\n",
    "            loss = self.classifier_loss_fn(valaro, pred)\n",
    "\n",
    "        # Get the gradients for the classifer\n",
    "        grads_F = tape.gradient(loss, self.classifer_F.trainable_variables)\n",
    "\n",
    "        # Update the weights of the classifer\n",
    "        self.classifer_F_optimizer.apply_gradients(\n",
    "            zip(grads_F, self.classifer_F.trainable_variables)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"F_loss\": loss,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9ffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classifier model\n",
    "valaro1 = ValaroModel1(\n",
    "    classifer_F=classi_F\n",
    ")\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "# Compile the model\n",
    "valaro1.compile(\n",
    "    classifer_F_optimizer=tf.keras.optimizers.SGD(learning_rate=2e-4, momentum=0.0),\n",
    "    classifier_loss_fn=mse,\n",
    ")\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8524c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66369733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class AccuracyMonitor(tf.keras.callbacks.Callback):\n",
    "    \"\"\"A callback to generate and save images after each epoch\"\"\"\n",
    "\n",
    "    def __init__(self, test_set):\n",
    "        self.ds_test = test_set\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "#         print(self.model.num_samples_used)\n",
    "        l2s = []\n",
    "        r2s = []\n",
    "        for i, data in enumerate(self.ds_test):\n",
    "            \n",
    "            lnds, valaros = data\n",
    "            pred = self.model.classifer_F(lnds)\n",
    "\n",
    "            l2s.append(tf.reduce_mean(tf.norm(pred-valaros, axis=-1)))\n",
    "            r2s.append(tf.constant(r2_score(pred.numpy(),valaros.numpy())))\n",
    "            \n",
    "        print(\"\\n Avg. L2:\", tf.reduce_mean(l2s))\n",
    "        print(\" Avg. R2:\", tf.reduce_mean(r2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cardinality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf983ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * ds.cardinality().numpy())\n",
    "# test_size = int(0.2 * ds.cardinality)\n",
    "\n",
    "train_ds = ds.take(train_size)\n",
    "test_ds = ds.skip(train_size)\n",
    "\n",
    "accmon = AccuracyMonitor(test_ds)\n",
    "\n",
    "valaro1.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    callbacks=[accmon, tensorboard_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ad9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal((1,136))\n",
    "pred = valaro1.classifer_F(x)\n",
    "\n",
    "y = tf.constant([[1.,1.]])\n",
    "y, pred\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# r2_score(pred.numpy(),y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.norm(pred-y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dd332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
