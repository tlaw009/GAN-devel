{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec4abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5d5b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/client'\n",
    "# d2 = '/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2/counselor'\n",
    "# # iterate over files in\n",
    "# # that directory\n",
    "\n",
    "# data_in = []\n",
    "# data_out = []\n",
    "# for filename in sorted(os.listdir(d1)):\n",
    "#     fn = os.path.join(d1, filename)\n",
    "#     if os.path.isfile(fn):\n",
    "#         with open(fn) as f:\n",
    "#             lines = f.readlines()\n",
    "#             aline = []\n",
    "#             for x in lines:\n",
    "#                 aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "#             data_in.append(aline)\n",
    "#         f.close()\n",
    "\n",
    "\n",
    "# for filename in sorted(os.listdir(d2)):\n",
    "#     fn = os.path.join(d2, filename)\n",
    "#     # checking if it is a file\n",
    "#     if os.path.isfile(fn):\n",
    "#         with open(fn) as f:\n",
    "#             lines = f.readlines()\n",
    "#             aline = []\n",
    "#             for x in lines:\n",
    "#                 aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "#             data_out.append(aline)\n",
    "#         f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa3994fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_in = data_in[:len(data_out)]\n",
    "# # print(tf.constant(data_in).shape)\n",
    "# # print(tf.constant(data_out).shape)\n",
    "\n",
    "# data = []\n",
    "# sequence_len = 16\n",
    "# ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "# ds = ds.batch(sequence_len)\n",
    "# ds = ds.shuffle(ds.cardinality().numpy())\n",
    "# for inn, outt in ds:\n",
    "#     print(inn.shape, outt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aad57b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GU(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2, emb_dim=512, gate_filters=32, num_resolutions=3, attn_res_idx=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.in_dim = in_dim\n",
    "        self.num_channels = num_channels\n",
    "        self.num_resolutions = num_resolutions\n",
    "        self.attn_res_idx = attn_res_idx\n",
    "        self.emb_dim = emb_dim\n",
    "        self.gate_filters = gate_filters\n",
    "#         self.model = self.build_graph()\n",
    "        \n",
    "#     def timestep_embedding(self, ts, embedding_dim):\n",
    "#         assert len(ts.shape)==1\n",
    "        \n",
    "#         half_dim = embedding_dim // 2\n",
    "#         emb = -(tf.math.log(10000.0)/(half_dim-1))\n",
    "        \n",
    "#         idxs = tf.range(half_dim, dtype=tf.float32)\n",
    "#         emb = tf.math.exp(idxs*emb)\n",
    "        \n",
    "#         ts = tf.cast(ts, dtype=tf.float32)\n",
    "        \n",
    "#         emb = ts[:,None]* emb[None,:]\n",
    "        \n",
    "#         pe = tf.concat([tf.sin(emb), tf.cos(emb)], axis=1)\n",
    "        \n",
    "#         return pe\n",
    "    \n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "        \n",
    "    def ResBlK(self, x, temb=None):\n",
    "        h = self.nonlinearity(self.normalize(x))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        if not temb == None:\n",
    "            temb = self.nonlinearity(temb)\n",
    "            h +=  tf.reshape(layers.Dense(h.shape[-1])(temb), (-1, 1, 1,h.shape[-1]))\n",
    "\n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        h = layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return x+h\n",
    "        \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "\n",
    "    def upsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2DTranspose(filters, (3, 3),\n",
    "                                       strides=(factor, factor), padding='same')(x)\n",
    "        \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdphi = tf.math.sqrt(tf.cast(phi.shape[1]*phi.shape[2]*phi.shape[3], tf.float32))\n",
    "        \n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)/srdphi\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def call(self, img_input):\n",
    "        \n",
    "        hs = [layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(img_input)]\n",
    "        \n",
    "        for i in range(self.num_resolutions):\n",
    "            h = self.ResBlK(hs[-1])\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)\n",
    "                \n",
    "            if i != self.num_resolutions - 1:\n",
    "                h = self.downsample(h, h.shape[-1]*2)\n",
    "                \n",
    "            hs.append(h)\n",
    "\n",
    "        h = hs[-1]\n",
    "        h = self.ResBlK(h)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h = self.ResBlK(h)\n",
    "                \n",
    "        for i in reversed(range(self.num_resolutions)):\n",
    "            if i == self.attn_res_idx:\n",
    "                h = self.NonlocalGaussian(h)   \n",
    "            h = self.ResBlK(h)\n",
    "            h = h+hs[i]\n",
    "                \n",
    "            if i != 0:\n",
    "                h = self.upsample(h, h.shape[-1]//2)\n",
    "                \n",
    "        h = self.nonlinearity(self.normalize(h))\n",
    "        \n",
    "        h = layers.Conv2D(self.num_channels, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        \n",
    "        return h\n",
    "    \n",
    "#     def call(self, x):\n",
    "#         return self.model([x])\n",
    "    \n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=(self.in_dim[0],\n",
    "                                        self.in_dim[1], self.num_channels))\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.num_channels))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72f5acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 18:23:51.181473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.188302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.188470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.189055: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 18:23:51.189778: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.189936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.190068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.482765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.482873: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.482950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-03 18:23:51.483016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5663 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "unet1=GU((16, 68))\n",
    "unet1.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd71dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = unet1.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "61008bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f35410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model1,to_file=\"./imgs/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cc71ba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tf.keras.utils.model_to_dot(model1, show_shapes=True, show_layer_activations=True).write_raw(\"model.dot\")\n",
    "# graph.write_raw(\"output_raw.dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88de40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        # self.dum = dum\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc)\n",
    "        self.g.build_graph()\n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def loss_func(self, pred_co, gt_co):\n",
    "        return tf.reduce_mean(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3]))\n",
    "        \n",
    "    @tf.function\n",
    "    def update(self, cl, co):\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            pred_co = self.g(cl)\n",
    "            g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "        grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "        return g_loss\n",
    "        \n",
    "    def train(self, epochs=50):\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.stack(batch_inn)\n",
    "                        tf_batch_outt = tf.stack(batch_outt)\n",
    "                        g_losses.append(self.update(tf_batch_inn, tf_batch_outt))\n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \"Generator Avg. Loss: \", np.mean(g_losses), flush=True)\n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f2b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afcc2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = model(ds_path, (8,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d575cfc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_490/372009434.py\", line 72, in update  *\n        pred_co = self.g(cl)\n    File \"/home/data_backup/miniconda3/envs/gan/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filep8gprssd.py\", line 10, in tf__call\n        hs = [ag__.converted_call(ag__.converted_call(ag__.ld(layers).Conv2D, (ag__.ld(self).gate_filters, (1, 1)), dict(strides=(1, 1), padding='same'), fscope), (ag__.ld(img_input),), None, fscope)]\n\n    TypeError: Exception encountered when calling layer \"gu_1\" (type GU).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_490/2143829761.py\", line 90, in call  *\n            hs = [layers.Conv2D(self.gate_filters, (1, 1),\n        File \"/home/data_backup/miniconda3/envs/gan/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n        \n        Input 'filter' of 'Conv2D' Op has type float32 that does not match type int32 of argument 'input'.\n        \n        Call arguments received by layer \"conv2d\" (type Conv2D):\n          • inputs=tf.Tensor(shape=(64, 8, 68, 2), dtype=int32)\n    \n    \n    Call arguments received by layer \"gu_1\" (type GU):\n      • img_input=tf.Tensor(shape=(64, 8, 68, 2), dtype=int32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36mmodel.train\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m     90\u001b[0m tf_batch_inn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(batch_inn)\n\u001b[1;32m     91\u001b[0m tf_batch_outt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(batch_outt)\n\u001b[0;32m---> 92\u001b[0m g_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_batch_inn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_batch_outt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     93\u001b[0m batch_inn \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     94\u001b[0m batch_outt \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileqk1ihcqc.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update\u001b[0;34m(self, cl, co)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m g_tape:\n\u001b[0;32m---> 11\u001b[0m     pred_co \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mg, (ag__\u001b[38;5;241m.\u001b[39mld(cl),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m     g_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mloss_func, (ag__\u001b[38;5;241m.\u001b[39mld(pred_co), ag__\u001b[38;5;241m.\u001b[39mld(co)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m grad_g \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(g_tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(g_loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m~/miniconda3/envs/gan/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filep8gprssd.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, img_input)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m hs \u001b[38;5;241m=\u001b[39m [ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(layers)\u001b[38;5;241m.\u001b[39mConv2D, (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mgate_filters, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mdict\u001b[39m(strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m), fscope), (ag__\u001b[38;5;241m.\u001b[39mld(img_input),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_2\u001b[39m():\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_490/372009434.py\", line 72, in update  *\n        pred_co = self.g(cl)\n    File \"/home/data_backup/miniconda3/envs/gan/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filep8gprssd.py\", line 10, in tf__call\n        hs = [ag__.converted_call(ag__.converted_call(ag__.ld(layers).Conv2D, (ag__.ld(self).gate_filters, (1, 1)), dict(strides=(1, 1), padding='same'), fscope), (ag__.ld(img_input),), None, fscope)]\n\n    TypeError: Exception encountered when calling layer \"gu_1\" (type GU).\n    \n    in user code:\n    \n        File \"/tmp/ipykernel_490/2143829761.py\", line 90, in call  *\n            hs = [layers.Conv2D(self.gate_filters, (1, 1),\n        File \"/home/data_backup/miniconda3/envs/gan/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        TypeError: Exception encountered when calling layer \"conv2d\" (type Conv2D).\n        \n        Input 'filter' of 'Conv2D' Op has type float32 that does not match type int32 of argument 'input'.\n        \n        Call arguments received by layer \"conv2d\" (type Conv2D):\n          • inputs=tf.Tensor(shape=(64, 8, 68, 2), dtype=int32)\n    \n    \n    Call arguments received by layer \"gu_1\" (type GU):\n      • img_input=tf.Tensor(shape=(64, 8, 68, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "m1.train(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aea8df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2a68e46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# batch_size=32\n",
    "# batch_inn = []\n",
    "# batch_outt = []\n",
    "\n",
    "\n",
    "# for inn, outt in m1.ds:\n",
    "#     if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "#         if (len(batch_inn))%batch_size ==0:\n",
    "#             tf_batch_inn = tf.stack(batch_inn)\n",
    "#             tf_batch_outt = tf.stack(batch_outt)\n",
    "#             if not tf_batch_inn.shape[0] == 0:\n",
    "#                 pred_out = m1.g(tf_batch_inn)\n",
    "#                 print(pred_out.shape)\n",
    "#             batch_inn = []\n",
    "#             batch_outt = []\n",
    "#             batch_inn.append(inn)\n",
    "#             batch_outt.append(outt)\n",
    "#         else:\n",
    "#             batch_inn.append(inn)\n",
    "#             batch_outt.append(outt)\n",
    "#         print(batch_outt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de67e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnD(Model):\n",
    "    \n",
    "    def __init__(self, in_dim ,num_out_filter=1,\n",
    "                  gate_filters=32):\n",
    "#                  stage_filters=(256,256,256,256,256,256,256), stage_kernels=(3,3,3,3,3,3,3), stage_strides_ds=(2,2,2,2,2,2)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # staging params must be equal\n",
    "        # assert len(stage_filters) == len(stage_kernels)\n",
    "        # assert len(stage_filters) == len(stage_strides_ds)+1\n",
    "        \n",
    "        self.gate_filters = gate_filters\n",
    "        self.in_dim = in_dim\n",
    "#         self.attn_shape = attn_shape\n",
    "        self.num_out_filter = num_out_filter\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "    \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdphi = tf.math.sqrt(tf.cast(phi.shape[1]*phi.shape[2]*phi.shape[3], tf.float32))\n",
    "        \n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)/srdphi\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "\n",
    "    def call(self, latent):\n",
    "        \n",
    "#         h = layers.Dense(self.attn_shape[0]*self.attn_shape[1]*self.gate_filters)(latent)\n",
    "#         h = layers.Reshape((self.attn_shape[0], self.attn_shape[1], self.gate_filters))(h)\n",
    "        h = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(latent)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(self.num_out_filter)(h)\n",
    "        h = self.nonlinearity(h)\n",
    "    \n",
    "        return h\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.in_dim)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.in_dim[2]))\n",
    "        \n",
    "    # def reproduce_model(self):\n",
    "    #     x = layers.Input(shape=(self.image_shape[0],\n",
    "    #                                     self.image_shape[1], self.num_channel))\n",
    "        \n",
    "    #     return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "#     def plot_models(self,path):\n",
    "#         rmodel = self.reproduce_model()\n",
    "#         tf.keras.utils.plot_model(rmodel, to_file=path+\"/model.png\", show_shapes=True, show_layer_activations=True)\n",
    "        \n",
    "#         idx = 0\n",
    "#         for resblk in self.resblks:\n",
    "#             tf.keras.utils.plot_model(resblk.reproduce_model(self.res_inshape[idx], (1,1)), to_file=path+\"/resblk_{:04d}.png\".format(idx), show_shapes=True, show_layer_activations=True)\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e969e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2AttnD(Model):\n",
    "    \n",
    "    def __init__(self, in_dim ,num_out_filter=1,\n",
    "                  gate_filters=32):\n",
    "#                  stage_filters=(256,256,256,256,256,256,256), stage_kernels=(3,3,3,3,3,3,3), stage_strides_ds=(2,2,2,2,2,2)):\n",
    "        \n",
    "        super().__init__()\n",
    "        # staging params must be equal\n",
    "        # assert len(stage_filters) == len(stage_kernels)\n",
    "        # assert len(stage_filters) == len(stage_strides_ds)+1\n",
    "        \n",
    "        self.gate_filters = gate_filters\n",
    "        self.in_dim = in_dim\n",
    "#         self.attn_shape = attn_shape\n",
    "        self.num_out_filter = num_out_filter\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def downsample(self, x, filters, factor=2):\n",
    "        return layers.Conv2D(filters, (3, 3),\n",
    "                                        strides=(factor, factor), padding='same')(x)\n",
    "    \n",
    "    def NonlocalGaussian(self, x):\n",
    "        h = self.normalize(x)\n",
    "        theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdphi = tf.math.sqrt(tf.cast(phi.shape[1]*phi.shape[2]*phi.shape[3], tf.float32))\n",
    "        \n",
    "        g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "        phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "        g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "        f = tf.matmul(theta, phi)/srdphi\n",
    "        \n",
    "        f = layers.Softmax()(f)\n",
    "        \n",
    "        y = tf.matmul(f, g)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "\n",
    "    def call(self, latent):\n",
    "        \n",
    "#         h = layers.Dense(self.attn_shape[0]*self.attn_shape[1]*self.gate_filters)(latent)\n",
    "#         h = layers.Reshape((self.attn_shape[0], self.attn_shape[1], self.gate_filters))(h)\n",
    "        h = layers.Conv2D(self.gate_filters, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(latent)\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = self.NonlocalGaussian(h)\n",
    "        h=self.downsample(h,int(self.gate_filters*2.))\n",
    "        h = layers.Flatten()(h)\n",
    "        h = layers.Dense(self.num_out_filter)(h)\n",
    "        h = self.nonlinearity(h)\n",
    "    \n",
    "        return h\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.in_dim)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))\n",
    "\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.in_dim[2]))\n",
    "        \n",
    "    # def reproduce_model(self):\n",
    "    #     x = layers.Input(shape=(self.image_shape[0],\n",
    "    #                                     self.image_shape[1], self.num_channel))\n",
    "        \n",
    "    #     return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "#     def plot_models(self,path):\n",
    "#         rmodel = self.reproduce_model()\n",
    "#         tf.keras.utils.plot_model(rmodel, to_file=path+\"/model.png\", show_shapes=True, show_layer_activations=True)\n",
    "        \n",
    "#         idx = 0\n",
    "#         for resblk in self.resblks:\n",
    "#             tf.keras.utils.plot_model(resblk.reproduce_model(self.res_inshape[idx], (1,1)), to_file=path+\"/resblk_{:04d}.png\".format(idx), show_shapes=True, show_layer_activations=True)\n",
    "#             idx += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e09acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = AttnD([16,68,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bed4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d86d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(d1, to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4d4e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4028407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPSILON = 1e-16\n",
    "\n",
    "class gan_model:\n",
    "    def __init__(self, dataset_path, data_shape, num_channels, dum=5, train_split=0.8,\n",
    "                 batch_size=64, lr=3e-4, gp_lam=10.0):\n",
    "        self.s = data_shape\n",
    "        self.nc = num_channels\n",
    "        self.bs = batch_size\n",
    "        self.gp_lam = gp_lam\n",
    "        self.dum = dum\n",
    "        self.in_shape = list(self.s)\n",
    "        self.in_shape.append(self.nc)\n",
    "        \n",
    "        if not dataset_path==None:\n",
    "            cl_path = dataset_path + \"/client\"\n",
    "            co_path = dataset_path + \"/counselor\"\n",
    "\n",
    "            self.ds = self.make_dataset(cl_path, co_path)\n",
    "            \n",
    "            ds_size = self.ds.cardinality().numpy()\n",
    "            train_size = int(train_split * ds_size)\n",
    "            # test_size = int((1.0-train_split) * ds_size)\n",
    "\n",
    "            self.train_ds = self.ds.take(train_size)    \n",
    "            self.test_ds = self.ds.skip(train_size)\n",
    "        else:\n",
    "            print(\"WARNING: Dataset not loaded, Model in Generator mode\")\n",
    "        \n",
    "        self.g = GU(self.s, self.nc).build_model()\n",
    "        self.d = AttnD(self.in_shape).build_model()\n",
    "\n",
    "        self.g_opt = tf.keras.optimizers.Adam(lr)\n",
    "        self.d_opt = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    def make_dataset(self, d1, d2):\n",
    "        data_in = []\n",
    "        data_out = []\n",
    "        for filename in sorted(os.listdir(d1)):\n",
    "            fn = os.path.join(d1, filename)\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_in.append(aline)\n",
    "                f.close()\n",
    "\n",
    "\n",
    "        for filename in sorted(os.listdir(d2)):\n",
    "            fn = os.path.join(d2, filename)\n",
    "            # checking if it is a file\n",
    "            if os.path.isfile(fn):\n",
    "                with open(fn) as f:\n",
    "                    lines = f.readlines()\n",
    "                    aline = []\n",
    "                    for x in lines:\n",
    "                        aline.append([int(y) for y in x.rstrip('\\n').split(\" \")[-2:]])\n",
    "                    data_out.append(aline)\n",
    "                f.close()\n",
    "\n",
    "        data_in = data_in[:len(data_out)]\n",
    "        # data = []\n",
    "        sequence_len = self.s[0]\n",
    "        ds = tf.data.Dataset.from_tensor_slices((tf.constant(data_in), tf.constant(data_out)))\n",
    "        ds = ds.batch(sequence_len)\n",
    "        ds = ds.shuffle(ds.cardinality().numpy())\n",
    "        \n",
    "        return ds\n",
    "    \n",
    "    def W_loss(self, d_data, d_gen, x_it):\n",
    "        \n",
    "        with tf.GradientTape() as t_gp:\n",
    "            t_gp.watch(x_it)\n",
    "            d_it = self.d(x_it)\n",
    "\n",
    "        gp_grad = t_gp.gradient(d_it, x_it)\n",
    "        l2n_gp = tf.math.sqrt(tf.reduce_sum(gp_grad**2, axis = [1,2,3])+EPSILON)\n",
    "        L_gp = self.gp_lam*(l2n_gp-1.0)**2\n",
    "\n",
    "        L_g = d_data - d_gen\n",
    "\n",
    "        L_d = -L_g + L_gp\n",
    "\n",
    "        return tf.nn.compute_average_loss(L_g), tf.nn.compute_average_loss(L_d)\n",
    "    \n",
    "    # def loss_func(self, pred_co, gt_co):\n",
    "    #     return tf.reduce_mean(tf.math.sqrt(tf.reduce_sum(tf.math.add(pred_co, -tf.cast(gt_co, tf.float32))**2, axis = [1,2,3])+EPSILON))\n",
    "        \n",
    "    # @tf.function\n",
    "    # def update(self, cl, co):\n",
    "    #     with tf.GradientTape() as g_tape:\n",
    "    #         pred_co = self.g(cl)\n",
    "    #         g_loss = self.loss_func(pred_co, co)\n",
    "            \n",
    "    #     grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "    #     self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "        \n",
    "    #     return g_loss\n",
    "    \n",
    "    @tf.function \n",
    "    def update(self, cl, co, update_gen=True):\n",
    "        \n",
    "        # noise_input = tf.random.normal((imgs.shape[0], self.latent_dim))\n",
    "            \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            gco = self.g(cl)\n",
    "\n",
    "            dx = self.d(co)\n",
    "            dg = self.d(gco)\n",
    "\n",
    "            epsi = tf.random.uniform([co.shape[0], 1, 1, 1], 0.0, 1.0)\n",
    "            co_it = tf.math.add(epsi*tf.cast(co,tf.float32), (1.0-epsi)*gco)\n",
    "\n",
    "            g_loss, d_loss = self.W_loss(dx, dg, co_it)\n",
    "\n",
    "        if update_gen:\n",
    "            grad_g = g_tape.gradient(g_loss, self.g.trainable_variables)\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "\n",
    "            self.g_opt.apply_gradients(zip(grad_g, self.g.trainable_variables))\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "        else:\n",
    "            grad_d = d_tape.gradient(d_loss, self.d.trainable_variables)\n",
    "            self.d_opt.apply_gradients(zip(grad_d, self.d.trainable_variables))\n",
    "\n",
    "        return g_loss, d_loss\n",
    "\n",
    "    def train(self, epochs=50):\n",
    "        num_training = 0\n",
    "        for epo in range(epochs):\n",
    "            g_losses = []\n",
    "            d_losses = []\n",
    "            \n",
    "            batch_inn = []\n",
    "            batch_outt = []\n",
    "\n",
    "            for inn, outt in self.train_ds:\n",
    "                if list(inn.shape) == self.in_shape and list(outt.shape) == self.in_shape:\n",
    "                    if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                        tf_batch_inn = tf.stack(batch_inn)\n",
    "                        tf_batch_outt = tf.stack(batch_outt)\n",
    "                        if num_training%self.dum == 0:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, True)\n",
    "                            g_losses.append(g_l.numpy())\n",
    "                        else:\n",
    "                            g_l, d_l = self.update(tf_batch_inn, tf_batch_outt, False)\n",
    "                        d_losses.append(d_l.numpy())\n",
    "\n",
    "                        num_training = (num_training+1)%self.dum\n",
    "                        \n",
    "                        batch_inn = []\n",
    "                        batch_outt = []\n",
    "                    else:\n",
    "                        batch_inn.append(inn)\n",
    "                        batch_outt.append(outt)\n",
    "\n",
    "\n",
    "            print(\"Epoch {:04d}\".format(epo), \" Generator Avg. Loss: \", np.mean(g_losses),\n",
    "                   \", Discriminator Avg. Loss: \", np.mean(d_losses), flush=True)\n",
    "            \n",
    "    def test(self):\n",
    "        errors = []\n",
    "        batch_inn = []\n",
    "        batch_outt = []\n",
    "        for inn, outt in self.test_ds:\n",
    "            if inn.shape == (8,68,2) and outt.shape == (8,68,2):\n",
    "                if (len(batch_inn))%self.bs ==0 and not len(batch_inn) == 0:\n",
    "                    tf_batch_inn = tf.stack(batch_inn)\n",
    "                    tf_batch_outt = tf.stack(batch_outt)\n",
    "                    pred_co = self.g(tf_batch_inn)\n",
    "                    errors.append(self.loss_func(pred_co, tf_batch_outt))\n",
    "                    batch_inn = []\n",
    "                    batch_outt = []\n",
    "                else:\n",
    "                    batch_inn.append(inn)\n",
    "                    batch_outt.append(outt)\n",
    "        print(\"Test Set Avg. Loss: \", np.mean(errors), flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93670578",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"/home/data_backup/data_bu/eva_dataset/materialForEEVA/images/session2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4280d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = gan_model(ds_path, (8,68), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9505f683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1bb42b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Avg. Loss:  7899.4136\n"
     ]
    }
   ],
   "source": [
    "gan.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a4fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class L2SAttn(layers.Layer):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def nonlinearity(self, x):\n",
    "#         return tf.keras.activations.swish(x)\n",
    "    \n",
    "#     def normalize(self, x):\n",
    "#         return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         h = self.normalize(x)\n",
    "#         theta = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         phi = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         g = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(h)\n",
    "#         phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "#         theta = tf.reshape(theta, shape=(-1, theta.shape[1]*theta.shape[2], theta.shape[3]))\n",
    "\n",
    "#         phi = tf.reshape(phi, shape=(-1, phi.shape[1], phi.shape[2]*phi.shape[3]))\n",
    "#         g = tf.reshape(g, shape=(-1, g.shape[1]*g.shape[2], g.shape[3]))\n",
    "        \n",
    "#         f = tf.matmul(theta, phi)\n",
    "        \n",
    "#         f = layers.Softmax()(f)\n",
    "        \n",
    "#         y = tf.matmul(f, g)\n",
    "        \n",
    "#         y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "#         z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "#                                         strides=(1, 1), padding='same')(y))\n",
    "#         return z\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ca529a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2SAttn_M(Model):\n",
    "\n",
    "    def __init__(self, in_dim, num_channels=2):\n",
    "        super().__init__()\n",
    "        # self.l2sattn1 = L2SAttn()\n",
    "        self.in_dim = in_dim\n",
    "        self.nc = num_channels\n",
    "        self.s = list(in_dim)\n",
    "        self.s.append(self.nc)\n",
    "\n",
    "    def nonlinearity(self, x):\n",
    "        return tf.keras.activations.swish(x)\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return tfa.layers.InstanceNormalization(axis=-1)(x)\n",
    "    \n",
    "    def call(self, x):\n",
    "        h = self.normalize(x)\n",
    "        Q = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        K = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2]*K.shape[3], tf.float32))\n",
    "        V = layers.Conv2D(x.shape[-1]/2.0, (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(h)\n",
    "        # phi = tf.transpose(phi, (0, 3, 2, 1))\n",
    "\n",
    "        Q = tf.reshape(Q, shape=(-1, Q.shape[1]*Q.shape[2], Q.shape[3]))\n",
    "\n",
    "        K = tf.reshape(K, shape=(-1, K.shape[1]*K.shape[2], K.shape[3]))\n",
    "        V = tf.reshape(V, shape=(-1, V.shape[1]*V.shape[2], V.shape[3]))\n",
    "        \n",
    "        rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "        f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "        f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "        f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "        f = (f1-2*f2+f3)/srdK\n",
    "        \n",
    "        f = layers.Softmax()(-f)\n",
    "        \n",
    "        y = tf.matmul(f, V)\n",
    "        \n",
    "        y = tf.reshape(y, (-1, x.shape[1], x.shape[2], y.shape[-1]))\n",
    "        \n",
    "        z = tf.math.add(x, layers.Conv2D(x.shape[-1], (1, 1),\n",
    "                                        strides=(1, 1), padding='same')(y))\n",
    "        return z\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.build(input_shape=(None,self.in_dim[0],\n",
    "                                        self.in_dim[1], self.nc))\n",
    "\n",
    "    def build_model(self):\n",
    "        x = layers.Input(shape=self.s)\n",
    "        \n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4630d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = L2SAttn_M((32,32), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1dd5c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3e5a8d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(a.build_model(),to_file=\"./model_plots/model.png\", show_shapes=True, show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "102d1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = tf.random.uniform(shape=(2, 64, 32))\n",
    "K = tf.random.uniform(shape=(2, 64, 32))\n",
    "\n",
    "rnQ = tf.reduce_sum(tf.math.square(Q), axis=-1, keepdims=True)\n",
    "f1 = tf.matmul(rnQ, tf.ones_like(rnQ), transpose_b=True)\n",
    "\n",
    "f2 = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "rnK = tf.reduce_sum(tf.math.square(K), axis=-1, keepdims=True)\n",
    "f3 = tf.matmul(tf.ones_like(rnK), rnK, transpose_b=True)\n",
    "\n",
    "srdK = tf.math.sqrt(tf.cast(K.shape[1]*K.shape[2], tf.float32))\n",
    "# srdK\n",
    "# f1, f2, f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "28fb3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.ones(shape=(None,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69331b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb542ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
